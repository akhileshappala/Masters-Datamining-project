{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "***\n",
    "**Name**: $<$insert name here$>$ \n",
    "***\n",
    "\n",
    "This assignment is due on Canvas by **9:30am on Thursday, September 15\n",
    "th 2021**. Submit only this Jupyter notebook to Canvas.  Do not compress it using tar, rar, zip, etc. Your solutions to analysis questions should be done in Markdown directly below the associated question.  Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules to be followed for the assignment are:\n",
    "\n",
    "- Do **NOT** load or use any Python packages that are not available in [Anaconda for Python 3.9](https://docs.anaconda.com/anaconda/packages/pkg-docs/). \n",
    "- Some problems with code may be autograded.  If we provide a function or class API **do not** change it.\n",
    "- Do not change the location of the data or data directory.  Use only relative paths to access the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:22:03.370195Z",
     "start_time": "2020-09-10T01:22:02.356211Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [50 points] Problem 1\n",
    "***\n",
    "\n",
    "There are two functions that need to be completed:\n",
    "\n",
    "#### normalization(fname, attr, normType, min_norm, max_norm)\n",
    "\n",
    "- This function takes in the relative_path + dataset_name, the attribute name that has to be normalised (one of the values from `'Open','High','Low','Close/Last','Volume'`), and the type of normalization to be performed (`'min_max'` or `'z_score'`)\n",
    "\n",
    "- Based on the normalization type that is provided, you will have to apply the appropriate formula and return a dictionary where `key = original_value` and  `value = normalised_value`\n",
    "\n",
    "- For `min_max` normalization, `[min_norm, max_norm]` will be the normalized range. The defualt normalization range would be [0, 1]. Note that for `z_score` normalization, `min_norm` and `max_norm` will not be used. \n",
    "\n",
    "#### correlation (fname1, attr1, fname2, attr2)\n",
    "\n",
    "- This function takes in the relative path + the name of the first data file, the attribute name that has to be used in the first file, the relative path + the name of the second data file,  and the attribute name that has to be used in the second file.\n",
    "\n",
    "- This function calculates the **Pearson's r correlation coefficient** between the two attributes mentioned in the two files.\n",
    "\n",
    "Note:\n",
    "- All the data and testing files are already under folder `data`. **Please maintain this as it would be necessary while grading.**\n",
    "- **Do not modify function `preprocess`.**\n",
    "- **Do not change the variable names of the returned values.**\n",
    "- If the test case fails, one way to debug is to see the output of the testing data and comparing it to your output.\n",
    "- Initially the test case will fail as there is no code in the below two functions.\n",
    "- You can assume there's no illeagal input, so you do not need to do input error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:24:30.995387Z",
     "start_time": "2020-09-10T01:24:30.990865Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(fname):\n",
    "    '''\n",
    "    A helper function provided to you to remove the $ symbols in the dataset and to convert data type for columns to float. \n",
    "    Input Parameters:\n",
    "        fname: (string) relative path + the name of the csv file containing historical quotes\n",
    "    Return:\n",
    "        df: A pandas dataframe with $ symbol removed from columns and data type of columns converted to float\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(fname)\n",
    "    df.columns = df.columns.str.replace(' ', '', regex=True)\n",
    "    \n",
    "    columns = [\"Close/Last\", \"Open\", \"High\", \"Low\"]\n",
    "    for column in columns:\n",
    "        df[column] = df[column].str.replace('$', '', regex=True)\n",
    "        df[column] = df[column].astype(float)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:24:33.428213Z",
     "start_time": "2020-09-10T01:24:33.423898Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalization (fname, attr, normType, min_norm=0, max_norm=1):\n",
    "    '''\n",
    "    Input Parameters:\n",
    "        fname: (string) relative path + the name of the csv file containing historical quotes\n",
    "        attr: (string) the name of attribute to be normalized \n",
    "        normType: (string) the type of normalization to be performed which can be either \"min_max\" or \"z_score\"\n",
    "        min_norm, max_norm: (int) min and max value for the normalized range when normType is \"min_max\" (Default 0 and 1)\n",
    "    Return:\n",
    "        result: a dictionary where each key is the original column value and each value is the normalized column value. \n",
    "    '''\n",
    "    # call the preprocess function to convert the data to float type and remove $ symbol in price column\n",
    "    df = preprocess(fname) \n",
    "    result = {\n",
    "    }\n",
    "    #TODO: Perform the indicated normalization type and return a dictionary in the shape {original_value:normalized_value, ...}\n",
    "\n",
    "    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:24:55.210777Z",
     "start_time": "2020-09-10T01:24:55.201476Z"
    }
   },
   "outputs": [],
   "source": [
    "def correlation (fname1, attr1, fname2, attr2):\n",
    "    '''\n",
    "    Input Parameters:\n",
    "        fname1: (string) relative path + the name of the first csv file containing historical quotes\n",
    "        attr1: (string) the name of attribute to consider in the first csv file (fname1)\n",
    "        fname2: (string) relative path + the name of the second csv file containing historical quotes\n",
    "        attr2: (string) the column name of attribute to consider in the second csv file (fname2)   \n",
    "    Return:\n",
    "        correlation_coefficient: (float in range -1 to + 1) Pearson's r correlation coefficient between attr1 in fname1 and attr2 in fname2\n",
    "    '''\n",
    "    \n",
    "\n",
    "    df1 = preprocess(fname1)\n",
    "    df2 = preprocess(fname2)\n",
    "    correlation_coefficient = 0.0  \n",
    "    #TODO: Wtire code to compute the Pearson's r correlation coefficient between attr1 in fname1 and attr2 in fname2.\n",
    "\n",
    "    \n",
    "    \n",
    "    return correlation_coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:28:36.101216Z",
     "start_time": "2020-09-10T01:28:36.049564Z"
    }
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class Test(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.loc1 = \"data/test1.csv\"\n",
    "        self.loc2 = \"data/test2.csv\"\n",
    "        file = open('data/test_normalization', 'rb')\n",
    "        testing_normalization_data = pickle.load(file)\n",
    "        self.min_norm, self.max_norm = testing_normalization_data[0]\n",
    "        self.data_normalization = testing_normalization_data[1]\n",
    "        file.close()\n",
    "        file = open('data/test_zscore', 'rb')\n",
    "        self.zscore = pickle.load(file)\n",
    "        file = open('data/test_correlation', 'rb')\n",
    "        self.data_correlation = pickle.load(file)\n",
    "        file.close()\n",
    "        \n",
    "    def test0(self):\n",
    "        \"\"\"\n",
    "        Test min_max normalization\n",
    "        \"\"\"\n",
    "        result = normalization(self.loc2, \"High\", \"min_max\", self.min_norm, self.max_norm)\n",
    "        for key,value in self.data_normalization.items():\n",
    "            self.assertAlmostEqual(result[key],value, places = 1)\n",
    "            \n",
    "    def test1(self):\n",
    "        \"\"\"\n",
    "        Test zcore normalization\n",
    "        \"\"\"\n",
    "        result = normalization(self.loc2, \"Open\", \"z_score\")\n",
    "        for key, value in self.zscore.items():\n",
    "            self.assertAlmostEqual(result[key], value, places = 1)\n",
    "    \n",
    "    def test2(self):\n",
    "        \"\"\"\n",
    "        Test correlation coefficient\n",
    "        \"\"\"\n",
    "        print(self.data_correlation)\n",
    "        result = correlation(self.loc1, \"Open\", self.loc2, \"Close/Last\")\n",
    "        self.assertAlmostEqual(result,self.data_correlation, places = 1)\n",
    "\n",
    "tests = Test()\n",
    "tests_to_run = unittest.TestLoader().loadTestsFromModule(tests)\n",
    "unittest.TextTestRunner().run(tests_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [50 points] Problem 2\n",
    "***\n",
    "\n",
    "Using the VOO 5-year Historical Quotes dataset, plot the following: \n",
    "\n",
    "(a) A single plot showing the temporal change of the “High” and “Low” attributes. \n",
    "\n",
    "(b) A boxplot for the “Open” and “Close/Last” attributes. \n",
    "\n",
    "(c) The 10-bin equal-width histogram for the “Volume” attribute. \n",
    "\n",
    "(d) Any other plot that interests you (using this VOO dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "data = pd.read_csv('data/VOO-5year.csv')\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: use this cell to plot the temporal change of the \"High\" and \"Low\" attributes\n",
    "# make sure to include graph legend to distinguish between the two lines \n",
    "# set plot size to 14\" x 7\"\n",
    "plt.rc('figure', figsize = (14, 7))\n",
    "# your code here \n",
    "# BEGIN\n",
    "\n",
    "# END\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: use this cell to plot a boxplot for the “Open” and “Close/Last” attributes.\n",
    "# make sure to include graph legend to distinguish between the two boxplots \n",
    "\n",
    "# your code here \n",
    "# BEGIN\n",
    "\n",
    "\n",
    "# END\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: use this cell to plot a 10-bin equal-width histogram for the “Volume” attribute. \n",
    "# your code here \n",
    "# BEGIN\n",
    "\n",
    "# END\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: use this cell to plot another graph of interest to you \n",
    "# your code here \n",
    "# BEGIN\n",
    "\n",
    "# END\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
