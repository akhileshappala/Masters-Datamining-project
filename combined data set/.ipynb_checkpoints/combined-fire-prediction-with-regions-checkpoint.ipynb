{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Normalization\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras as keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from utils import run_all_regressors\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre-processing and EDA(Exploratory data analysis)\n",
    "Data Cleaning and filtering data which has firesize <5000 as number of small fires are high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def akReadDf():\n",
    "    # Reading the combined CSV files\n",
    "    df = pd.read_csv('Wildfire.csv')\n",
    "    df = df.drop(columns=['Unnamed: 0', 'Unnamed: 0.1','disc_date_final','cont_date_final','cont_clean_date','putout_time'])\n",
    "    df['disc_clean_date'] = pd.to_datetime(df['disc_clean_date'], format='%m/%d/%Y')\n",
    "\n",
    "    #Get rid of outliers - fires of size larger than 5000 acres, and there are large number of small fires and other very less number are having the high \n",
    "    # area of fires, because of which the deviation is very high\n",
    "    df = df.loc[df['fire_size'] < 5000]\n",
    "    df.columns\n",
    "\n",
    "    ################\n",
    "    df['Vegetation'] = df['Vegetation'].astype('category')\n",
    "    df['Cause'] = df['stat_cause_descr'].astype('category')\n",
    "\n",
    "    df = pd.get_dummies(df,prefix=['Vegetation'], columns = ['Vegetation'], drop_first=True)\n",
    "    df = pd.get_dummies(df,prefix=['Cause'], columns = ['stat_cause_descr'], drop_first=True)\n",
    "\n",
    "    ################\n",
    "    df_numerics_only = df.select_dtypes(include=np.number)\n",
    "\n",
    "    corr = df_numerics_only.corr()\n",
    "    ax = sns.heatmap(\n",
    "        corr, \n",
    "        vmin=-1, vmax=1, center=0,\n",
    "        cmap=sns.diverging_palette(220, 20, n=200),\n",
    "        square=True\n",
    "    )\n",
    "    ax.set_xticklabels(\n",
    "        ax.get_xticklabels(),\n",
    "        rotation=45,\n",
    "        horizontalalignment='right'\n",
    "    );\n",
    "    sns.set(rc={'figure.figsize':(15,15)})\n",
    "\n",
    "    ################\n",
    "    #Dealing with missing data\n",
    "    print(len(df))\n",
    "\n",
    "    # drop columns where weather_file is missing in the data, as it wont have the weather situation at that time, so its where ever data is \n",
    "    #missing we can remove those rows as it wont be useful\n",
    "    index = df[df['weather_file'] == 'File Not Found'].index\n",
    "    df.drop(index, inplace = True)\n",
    "    print(len(df))\n",
    "\n",
    "\n",
    "    ################\n",
    "    # Weather data has a lot of 0 and values some of which may be missing values,\n",
    "    # Mark '0' values in weather columns as Na (to see how many there are) \n",
    "    # As 0 wont add any value to the data, we are converting to NA and then removing them which will make data set\n",
    "    subset0 = ['Temp_pre_30','Temp_pre_15','Temp_pre_7','Temp_cont','Wind_pre_30','Wind_pre_15','Wind_pre_7','Wind_cont','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Hum_cont']\n",
    "    df[subset0] = df[subset0].replace({0:np.nan, '0':np.nan})\n",
    "    print(len(df))\n",
    "\n",
    "    # Mark '-1' as missing\n",
    "    subset_neg1 = ['Temp_pre_30','Temp_pre_15','Temp_pre_7','Temp_cont','Wind_pre_30','Wind_pre_15','Wind_pre_7','Wind_cont','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Hum_cont','Prec_pre_30','Prec_pre_15','Prec_pre_7','Prec_cont']\n",
    "    df[subset_neg1] = df[subset_neg1].replace({-1:np.nan})\n",
    "\n",
    "    # Drop observations where all weather columns are 0\n",
    "    df = df.dropna(how='all',\n",
    "                        subset=['Temp_pre_30','Temp_pre_15','Temp_pre_7','Temp_cont','Wind_pre_30','Wind_pre_15','Wind_pre_7','Wind_cont',])\n",
    "    print(len(df))\n",
    "    # This leaves us with 38,689 observations  +/- 3,000  to work with (originally we had 50,000)\n",
    "\n",
    "    ################\n",
    "    # fill the 'pre' columns temp wind and humidity with mean values\n",
    "    subset_fill_mean = ['Temp_pre_30','Temp_pre_15','Temp_pre_7', 'Wind_pre_30','Wind_pre_15','Wind_pre_7', 'Hum_pre_30', 'Hum_pre_15','Hum_pre_7']\n",
    "    df[subset_fill_mean] = df[subset_fill_mean].fillna(df[subset_fill_mean].mean())\n",
    "\n",
    "    # Fill NAs in the date of fire containment based on mean values from previous days\n",
    "    for col in ['Temp','Wind','Hum']:\n",
    "        df[f'{col}_cont'] = df.apply(\n",
    "            lambda row: (row[f'{col}_pre_7']+row[f'{col}_pre_15']+row[f'{col}_pre_30'])/3 if np.isnan(row[f'{col}_cont']) else row[f'{col}_cont'],\n",
    "            axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing region 1 dataframe...\n",
      "Grabbing region 2 dataframe...\n",
      "Grabbing region 3 dataframe...\n",
      "Grabbing region 4 dataframe...\n",
      "Grabbing region 5 dataframe...\n",
      "Grabbing region 6 dataframe...\n",
      "Grabbing region 8 dataframe...\n",
      "Grabbing region 9 dataframe...\n",
      "Grabbing region 10 dataframe...\n"
     ]
    }
   ],
   "source": [
    "from loadDFRegion import getDF\n",
    "df,dfRegionList = getDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1445578 1445578\n"
     ]
    }
   ],
   "source": [
    "#Sanity Check !!\n",
    "sum1=0\n",
    "ct=1\n",
    "for dftemp in dfRegionList:\n",
    "    if(ct>=7):\n",
    "        ct+=1\n",
    "    #print(ct, dftemp.size)\n",
    "    sum1+= dftemp.size\n",
    "print(df.size, sum1)\n",
    "assert(sum1==df.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experimentCreation_FireSizePrediction(df,yTarget):\n",
    "    \"\"\"Function return all experiments splitting data by yTarget name: \n",
    "        regression - fire_size\n",
    "        classification - fire_cause\n",
    "    \"\"\"\n",
    "    \n",
    "    # Experiment 1 \n",
    "    \"\"\"\n",
    "    - which will select all teh available  features from the dataset\n",
    "    -Features included - variables related to Vegetation,Temperature, Humidity, Wind, Precipitation, cause of  fire, longitude and latitude\n",
    "    - we have 34 variables  for x-variables  to which we are gonna target one y-variable which is fire_size\n",
    "    - selecting features and target variables\"\"\"\n",
    "    X1 = df[['Vegetation','remoteness','latitude','Temp_pre_30','Temp_pre_15','Temp_pre_7','Temp_cont','Wind_pre_30','Wind_pre_15','Wind_pre_7','Wind_cont','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Hum_cont','Prec_pre_30','Prec_pre_15','Prec_pre_7','Prec_cont','stat_cause_desc', 'longitude']]\n",
    "    #X1 = df[['Vegetation_4','remoteness', 'Vegetation_9','Vegetation_12','Vegetation_14','Vegetation_15','Vegetation_16','latitude','Temp_pre_30','Temp_pre_15','Temp_pre_7','Temp_cont','Wind_pre_30','Wind_pre_15','Wind_pre_7','Wind_cont','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Hum_cont','Prec_pre_30','Prec_pre_15','Prec_pre_7','Prec_cont','Cause_Debris Burning','Cause_Equipment Use','Cause_Fireworks','Cause_Lightning','Cause_Miscellaneous','Cause_Missing/Undefined','Cause_Powerline','Cause_Railroad','Cause_Smoking','Cause_Structure', 'longitude']]\n",
    "    # X1 = df[['Vegetation_4','Vegetation_9','Vegetation_12','Vegetation_14','Vegetation_15','Vegetation_16','latitude','Temp_pre_30','Temp_pre_15','Temp_pre_7','Temp_cont','Wind_pre_30','Wind_pre_15','Wind_pre_7','Wind_cont','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Hum_cont','Prec_pre_30','Prec_pre_15','Prec_pre_7','Prec_cont','Cause_Debris Burning','Cause_Equipment Use','Cause_Fireworks','Cause_Lightning','Cause_Miscellaneous','Cause_Missing/Undefined','Cause_Powerline','Cause_Railroad','Cause_Smoking','Cause_Structure', 'longitude']]\n",
    "\n",
    "    y = df[yTarget] \n",
    "\n",
    "    #train test split\n",
    "    X1_train, X1_test, y_train, y_test = train_test_split(X1, y, test_size=0.2, random_state=42)\n",
    "    df1 = [X1_train, X1_test, y_train, y_test]\n",
    "    #######################\n",
    "    #Experiment type 2 \n",
    "    \"\"\"-Include only long, lat, vegetation, cause and pre- weather data, without cont\n",
    "    - which is the data set where I removed the variables  on which the fire is  containining on the day\n",
    "    - removed 4 variables\n",
    "    - selecting features and target variables\"\"\"\n",
    "    X2 = df[['Vegetation','latitude','Temp_pre_30','Temp_pre_15','Temp_pre_7','Wind_pre_30','Wind_pre_15','Wind_pre_7','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Prec_pre_30','Prec_pre_15','Prec_pre_7','stat_cause_desc', 'longitude']]\n",
    "    #X2 = df[['Vegetation_4','Vegetation_9','Vegetation_12','Vegetation_14','Vegetation_15','Vegetation_16','latitude','Temp_pre_30','Temp_pre_15','Temp_pre_7','Wind_pre_30','Wind_pre_15','Wind_pre_7','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Prec_pre_30','Prec_pre_15','Prec_pre_7','Cause_Debris Burning','Cause_Equipment Use','Cause_Fireworks','Cause_Lightning','Cause_Miscellaneous','Cause_Missing/Undefined','Cause_Powerline','Cause_Railroad','Cause_Smoking','Cause_Structure', 'longitude']]\n",
    "    y = df[yTarget]\n",
    "\n",
    "    #train test split\n",
    "    X2_train, X2_test, y_train, y_test = train_test_split(X2, y, test_size=0.2, random_state=42)\n",
    "    df2 = [X2_train, X2_test, y_train, y_test]\n",
    "    ########################\n",
    "    #Experiment 3 \n",
    "    #- Including only lat, long and weather pre- data\n",
    "    #When I have done the feature importance, I got to know that the cause and vegetation is not that important, so here we removed the 2 \n",
    "    #  selecting features and target variables\n",
    "    X3 = df[['latitude','longitude','Temp_pre_30','Temp_pre_15','Temp_pre_7','Wind_pre_30','Wind_pre_15','Wind_pre_7','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Prec_pre_30','Prec_pre_15','Prec_pre_7']]\n",
    "    y = df[yTarget]\n",
    "\n",
    "    #train test split\n",
    "    X3_train, X3_test, y_train, y_test = train_test_split(X3, y, test_size=0.2, random_state=42)\n",
    "    df3 = [X3_train, X3_test, y_train, y_test]\n",
    "    \n",
    "    ########################\n",
    "    #Experiment 4 \n",
    "    #with experiment 1 data with normalization\n",
    "    # have done the minMax normalization for the experiment 1 data frame.\n",
    "    df_4 = df[['Vegetation','latitude','Temp_pre_30','Temp_pre_15','Temp_pre_7','Temp_cont','Wind_pre_30','Wind_pre_15','Wind_pre_7','Wind_cont','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Hum_cont','Prec_pre_30','Prec_pre_15','Prec_pre_7','Prec_cont','stat_cause_desc', 'longitude']]\n",
    "    names = df_4.columns\n",
    "\n",
    "    # normalizing data\n",
    "    df_4 = preprocessing.normalize(df_4)\n",
    "    scaled_df = pd.DataFrame(df_4, columns=names)\n",
    "\n",
    "    #train test split\n",
    "    X4_train, X4_test, y_train, y_test = train_test_split(scaled_df, y, test_size=0.2, random_state=42)\n",
    "    df4 = [X4_train, X4_test, y_train, y_test]\n",
    "    \n",
    "    return [df1,df2,df3,df4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running all regression models on all experiments for Prediction on Fire Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "____Running all experiments for Region 1____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9802185520772947\n",
      "Score on testing data: 0.8679309062586006\n",
      "Mean Absolute Error:  0.038127723630631744\n",
      "R Squared:  0.8679309062586006\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9743691746910226\n",
      "Score on testing data: 0.854812394338564\n",
      "Mean Absolute Error:  0.038877218327901746\n",
      "R Squared:  0.854812394338564\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999760149556\n",
      "Score on testing data: 0.8298083336446657\n",
      "Mean Absolute Error:  0.038144774059926764\n",
      "R Squared:  0.8298083336446657\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999760149556\n",
      "Score on testing data: 0.8599808485903878\n",
      "Mean Absolute Error:  0.03788734458200143\n",
      "R Squared:  0.8599808485903878\n",
      "\n",
      "Running SVR\n",
      "Score on training data: 0.023669598559045824\n",
      "Score on testing data: 0.006796051146053861\n",
      "Mean Absolute Error:  0.16133878041211616\n",
      "R Squared:  0.006796051146053861\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8802241027748111\n",
      "Score on testing data: 0.10097251931020279\n",
      "Mean Absolute Error:  0.14004728971970948\n",
      "R Squared:  0.10097251931020279\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.6883956022728843\n",
      "Score on testing data: 0.13105603661399212\n",
      "Mean Absolute Error:  0.13148864712073957\n",
      "R Squared:  0.13105603661399212\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999760149556\n",
      "Score on testing data: -0.9383807144140472\n",
      "Mean Absolute Error:  0.16591033665282925\n",
      "R Squared:  -0.9383807144140472\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999760149556\n",
      "Score on testing data: 0.13281543196487677\n",
      "Mean Absolute Error:  0.1345257125758246\n",
      "R Squared:  0.13281543196487677\n",
      "\n",
      "Running SVR\n",
      "Score on training data: 0.0030729201263411943\n",
      "Score on testing data: 0.0005391379981670719\n",
      "Mean Absolute Error:  0.16243481951503844\n",
      "R Squared:  0.0005391379981670719\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8715726803855157\n",
      "Score on testing data: 0.1160400210442234\n",
      "Mean Absolute Error:  0.14282125213247043\n",
      "R Squared:  0.1160400210442234\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.6794504053863665\n",
      "Score on testing data: 0.09696614788011904\n",
      "Mean Absolute Error:  0.13748028921657038\n",
      "R Squared:  0.09696614788011904\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999760149556\n",
      "Score on testing data: -0.5065667263568889\n",
      "Mean Absolute Error:  0.13882439932606414\n",
      "R Squared:  -0.5065667263568889\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999760149556\n",
      "Score on testing data: 0.12133387628459458\n",
      "Mean Absolute Error:  0.13860024543185154\n",
      "R Squared:  0.12133387628459458\n",
      "\n",
      "Running SVR\n",
      "Score on training data: 0.0019999229089440185\n",
      "Score on testing data: 2.110578852598799e-05\n",
      "Mean Absolute Error:  0.1625653536584315\n",
      "R Squared:  2.110578852598799e-05\n",
      "\n",
      "\n",
      "--------------Experiment 4--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8815253630044141\n",
      "Score on testing data: 0.1901756964315039\n",
      "Mean Absolute Error:  0.13327264419062926\n",
      "R Squared:  0.1901756964315039\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7176392527696083\n",
      "Score on testing data: 0.21735031129811377\n",
      "Mean Absolute Error:  0.1244481164301761\n",
      "R Squared:  0.21735031129811377\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999760149556\n",
      "Score on testing data: -0.8067402075097883\n",
      "Mean Absolute Error:  0.1601622460535033\n",
      "R Squared:  -0.8067402075097883\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999760149556\n",
      "Score on testing data: 0.19513908455402762\n",
      "Mean Absolute Error:  0.13149128967814935\n",
      "R Squared:  0.19513908455402762\n",
      "\n",
      "Running SVR\n",
      "Score on training data: 0.012994005440901124\n",
      "Score on testing data: 0.005589996656887086\n",
      "Mean Absolute Error:  0.1615866530692284\n",
      "R Squared:  0.005589996656887086\n",
      "\n",
      "____________________________________________\n",
      "\n",
      "\n",
      "____Running all experiments for Region 2____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9597396807287967\n",
      "Score on testing data: 0.6404695740972389\n",
      "Mean Absolute Error:  0.04751856221962242\n",
      "R Squared:  0.6404695740972389\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9051818852303684\n",
      "Score on testing data: 0.672108212602953\n",
      "Mean Absolute Error:  0.044908979937677854\n",
      "R Squared:  0.672108212602953\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.2861918342799159\n",
      "Mean Absolute Error:  0.05205152538207517\n",
      "R Squared:  0.2861918342799159\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.8148825110492605\n",
      "Mean Absolute Error:  0.03486456474767063\n",
      "R Squared:  0.8148825110492605\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -0.023215636280210505\n",
      "Score on testing data: -0.04681376121657599\n",
      "Mean Absolute Error:  0.13077681003132435\n",
      "R Squared:  -0.04681376121657599\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8747027778676524\n",
      "Score on testing data: 0.010485458467142217\n",
      "Mean Absolute Error:  0.09927068830577102\n",
      "R Squared:  0.010485458467142217\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.5574297505877059\n",
      "Score on testing data: -0.0027237926452279293\n",
      "Mean Absolute Error:  0.0991095518316536\n",
      "R Squared:  -0.0027237926452279293\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.8032497903673417\n",
      "Mean Absolute Error:  0.09463635363146185\n",
      "R Squared:  -0.8032497903673417\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.015971886915803535\n",
      "Mean Absolute Error:  0.09761276330173896\n",
      "R Squared:  0.015971886915803535\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -0.03526305312195466\n",
      "Score on testing data: -0.04977473513745534\n",
      "Mean Absolute Error:  0.13174746343719795\n",
      "R Squared:  -0.04977473513745534\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8582917136200858\n",
      "Score on testing data: -0.011220445841870319\n",
      "Mean Absolute Error:  0.10116576105658465\n",
      "R Squared:  -0.011220445841870319\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.5303965631544492\n",
      "Score on testing data: -0.057772593105377634\n",
      "Mean Absolute Error:  0.10172081631523643\n",
      "R Squared:  -0.057772593105377634\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -1.2056229711995776\n",
      "Mean Absolute Error:  0.11209701410914341\n",
      "R Squared:  -1.2056229711995776\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.05906995066934995\n",
      "Mean Absolute Error:  0.10374793082835537\n",
      "R Squared:  -0.05906995066934995\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -0.03562359210108035\n",
      "Score on testing data: -0.05005095156635608\n",
      "Mean Absolute Error:  0.13175324320599052\n",
      "R Squared:  -0.05005095156635608\n",
      "\n",
      "\n",
      "--------------Experiment 4--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8771303213862747\n",
      "Score on testing data: 0.15582162232481356\n",
      "Mean Absolute Error:  0.09036603709723738\n",
      "R Squared:  0.15582162232481356\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.6143274460690014\n",
      "Score on testing data: 0.1006822394015755\n",
      "Mean Absolute Error:  0.08950295997700106\n",
      "R Squared:  0.1006822394015755\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.8308293128827842\n",
      "Mean Absolute Error:  0.09429914018719895\n",
      "R Squared:  -0.8308293128827842\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.12478948162837333\n",
      "Mean Absolute Error:  0.09090216839454038\n",
      "R Squared:  0.12478948162837333\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -0.025777788302464133\n",
      "Score on testing data: -0.04360751739164348\n",
      "Mean Absolute Error:  0.1306322161419359\n",
      "R Squared:  -0.04360751739164348\n",
      "\n",
      "____________________________________________\n",
      "\n",
      "\n",
      "____Running all experiments for Region 3____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "Running RandomForestRegressor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training data: 0.9807379068090071\n",
      "Score on testing data: 0.8875269462244004\n",
      "Mean Absolute Error:  0.03442766976846553\n",
      "R Squared:  0.8875269462244004\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.990398266838978\n",
      "Score on testing data: 0.8702734948362223\n",
      "Mean Absolute Error:  0.03135386501707144\n",
      "R Squared:  0.8702734948362223\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999999786066\n",
      "Score on testing data: 0.8065455868788571\n",
      "Mean Absolute Error:  0.03869420421057478\n",
      "R Squared:  0.8065455868788571\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999999786066\n",
      "Score on testing data: 0.9054129813653979\n",
      "Mean Absolute Error:  0.0316598159929155\n",
      "R Squared:  0.9054129813653979\n",
      "\n",
      "Running SVR\n",
      "Score on training data: 0.007271681249555018\n",
      "Score on testing data: -0.015003288967290862\n",
      "Mean Absolute Error:  0.15552859354597787\n",
      "R Squared:  -0.015003288967290862\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8784341870516417\n",
      "Score on testing data: 0.10659627027954688\n",
      "Mean Absolute Error:  0.12506171392956283\n",
      "R Squared:  0.10659627027954688\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7094337974643848\n",
      "Score on testing data: -0.007798749984123443\n",
      "Mean Absolute Error:  0.1305104812832862\n",
      "R Squared:  -0.007798749984123443\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999999786066\n",
      "Score on testing data: -0.5117748954497308\n",
      "Mean Absolute Error:  0.1260391896403152\n",
      "R Squared:  -0.5117748954497308\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999999786066\n",
      "Score on testing data: 0.16761214008211356\n",
      "Mean Absolute Error:  0.1163156766578193\n",
      "R Squared:  0.16761214008211356\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -0.0028339718929060176\n",
      "Score on testing data: -0.022178133328341954\n",
      "Mean Absolute Error:  0.15612435677153305\n",
      "R Squared:  -0.022178133328341954\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8832841140603889\n",
      "Score on testing data: 0.07092725054426141\n",
      "Mean Absolute Error:  0.1294496885798876\n",
      "R Squared:  0.07092725054426141\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7209561116349057\n",
      "Score on testing data: 0.028848120722863912\n",
      "Mean Absolute Error:  0.1322989738728587\n",
      "R Squared:  0.028848120722863912\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999999786066\n",
      "Score on testing data: -0.48558118681749773\n",
      "Mean Absolute Error:  0.12563499238597045\n",
      "R Squared:  -0.48558118681749773\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999999786066\n",
      "Score on testing data: 0.11208757297286054\n",
      "Mean Absolute Error:  0.12442194067717174\n",
      "R Squared:  0.11208757297286054\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -0.003804575637328167\n",
      "Score on testing data: -0.023805650363531328\n",
      "Mean Absolute Error:  0.15623710769283278\n",
      "R Squared:  -0.023805650363531328\n",
      "\n",
      "\n",
      "--------------Experiment 4--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8596724463203\n",
      "Score on testing data: -0.08613889272881603\n",
      "Mean Absolute Error:  0.12974352502570902\n",
      "R Squared:  -0.08613889272881603\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.739281307889782\n",
      "Score on testing data: -0.08893451220337245\n",
      "Mean Absolute Error:  0.1301343794767346\n",
      "R Squared:  -0.08893451220337245\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999999786066\n",
      "Score on testing data: -1.1796012567446321\n",
      "Mean Absolute Error:  0.1601883382832748\n",
      "R Squared:  -1.1796012567446321\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999999786066\n",
      "Score on testing data: -0.0031447504081139055\n",
      "Mean Absolute Error:  0.12913438422974968\n",
      "R Squared:  -0.0031447504081139055\n",
      "\n",
      "Running SVR\n",
      "Score on training data: 0.00039330644894342015\n",
      "Score on testing data: -0.003058652683498586\n",
      "Mean Absolute Error:  0.1544258774036163\n",
      "R Squared:  -0.003058652683498586\n",
      "\n",
      "____________________________________________\n",
      "\n",
      "\n",
      "____Running all experiments for Region 4____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9756736154163953\n",
      "Score on testing data: 0.8092845399807367\n",
      "Mean Absolute Error:  0.07669580378604947\n",
      "R Squared:  0.8092845399807367\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.931085068681722\n",
      "Score on testing data: 0.7877392614764481\n",
      "Mean Absolute Error:  0.07982949129862313\n",
      "R Squared:  0.7877392614764481\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.6949088070378365\n",
      "Mean Absolute Error:  0.0832014711493552\n",
      "R Squared:  0.6949088070378365\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.8175055124268299\n",
      "Mean Absolute Error:  0.07283581365858655\n",
      "R Squared:  0.8175055124268299\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -0.041617571247722474\n",
      "Score on testing data: -0.08033336420138082\n",
      "Mean Absolute Error:  0.2309731696055511\n",
      "R Squared:  -0.08033336420138082\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8651287623012947\n",
      "Score on testing data: 0.03445945517692517\n",
      "Mean Absolute Error:  0.2512652582469223\n",
      "R Squared:  0.03445945517692517\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.4390461083234444\n",
      "Score on testing data: 0.044489839652441465\n",
      "Mean Absolute Error:  0.245912985007883\n",
      "R Squared:  0.044489839652441465\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.6876418010375815\n",
      "Mean Absolute Error:  0.2629840220738753\n",
      "R Squared:  -0.6876418010375815\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.03923117788905417\n",
      "Mean Absolute Error:  0.24406924933143126\n",
      "R Squared:  0.03923117788905417\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -0.05346753864224518\n",
      "Score on testing data: -0.08624537388635445\n",
      "Mean Absolute Error:  0.23115241704955589\n",
      "R Squared:  -0.08624537388635445\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8639453674740788\n",
      "Score on testing data: 0.0492510441594205\n",
      "Mean Absolute Error:  0.24881993715764955\n",
      "R Squared:  0.0492510441594205\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.4330414109583294\n",
      "Score on testing data: 0.06402325277017484\n",
      "Mean Absolute Error:  0.24294028100824147\n",
      "R Squared:  0.06402325277017484\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.6611464486712364\n",
      "Mean Absolute Error:  0.25965107658636016\n",
      "R Squared:  -0.6611464486712364\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.058780118332357745\n",
      "Mean Absolute Error:  0.24300707954822925\n",
      "R Squared:  0.058780118332357745\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -0.05442374986763654\n",
      "Score on testing data: -0.08691039936448242\n",
      "Mean Absolute Error:  0.2311290797030254\n",
      "R Squared:  -0.08691039936448242\n",
      "\n",
      "\n",
      "--------------Experiment 4--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8698173530633853\n",
      "Score on testing data: 0.07457532196127958\n",
      "Mean Absolute Error:  0.2434959025626656\n",
      "R Squared:  0.07457532196127958\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.4686939548210981\n",
      "Score on testing data: 0.07792293218568491\n",
      "Mean Absolute Error:  0.2426050119971662\n",
      "R Squared:  0.07792293218568491\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -1.0217806361875583\n",
      "Mean Absolute Error:  0.2962505194315475\n",
      "R Squared:  -1.0217806361875583\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.0909765365691324\n",
      "Mean Absolute Error:  0.2383519887711354\n",
      "R Squared:  0.0909765365691324\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -0.0452919519993753\n",
      "Score on testing data: -0.08349156067523311\n",
      "Mean Absolute Error:  0.23125211211352537\n",
      "R Squared:  -0.08349156067523311\n",
      "\n",
      "____________________________________________\n",
      "\n",
      "\n",
      "____Running all experiments for Region 5____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9808272672813698\n",
      "Score on testing data: 0.8796347763060499\n",
      "Mean Absolute Error:  0.022566329767563367\n",
      "R Squared:  0.8796347763060499\n",
      "\n",
      "Running GradientBoostingRegressor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training data: 0.9540695813207151\n",
      "Score on testing data: 0.9044306453058064\n",
      "Mean Absolute Error:  0.019805321806126437\n",
      "R Squared:  0.9044306453058064\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999998887213692\n",
      "Score on testing data: 0.7374743493087104\n",
      "Mean Absolute Error:  0.027559920511661135\n",
      "R Squared:  0.7374743493087104\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999998887213692\n",
      "Score on testing data: 0.8534402129562957\n",
      "Mean Absolute Error:  0.02548071138079128\n",
      "R Squared:  0.8534402129562957\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -0.08044109200393224\n",
      "Score on testing data: -0.09296565901862852\n",
      "Mean Absolute Error:  0.12595148640027584\n",
      "R Squared:  -0.09296565901862852\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8704237807488753\n",
      "Score on testing data: 0.0888957673313987\n",
      "Mean Absolute Error:  0.08360321088669871\n",
      "R Squared:  0.0888957673313987\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.42807631741640495\n",
      "Score on testing data: 0.0283717116232578\n",
      "Mean Absolute Error:  0.0801566993688753\n",
      "R Squared:  0.0283717116232578\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999998887213692\n",
      "Score on testing data: -0.9171643657787212\n",
      "Mean Absolute Error:  0.0807191154468835\n",
      "R Squared:  -0.9171643657787212\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999998887213692\n",
      "Score on testing data: 0.02714206258219809\n",
      "Mean Absolute Error:  0.08447187537834168\n",
      "R Squared:  0.02714206258219809\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -0.0825201438361014\n",
      "Score on testing data: -0.09488152867161914\n",
      "Mean Absolute Error:  0.12603236128816875\n",
      "R Squared:  -0.09488152867161914\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8614016648951828\n",
      "Score on testing data: 0.07227726134835044\n",
      "Mean Absolute Error:  0.08275285805689793\n",
      "R Squared:  0.07227726134835044\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.4194121984285739\n",
      "Score on testing data: 0.020878285082504555\n",
      "Mean Absolute Error:  0.0806117413025773\n",
      "R Squared:  0.020878285082504555\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999998887213692\n",
      "Score on testing data: -0.7986784557744582\n",
      "Mean Absolute Error:  0.07711796989409067\n",
      "R Squared:  -0.7986784557744582\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999998887213692\n",
      "Score on testing data: 0.049428063268914135\n",
      "Mean Absolute Error:  0.08559279850097384\n",
      "R Squared:  0.049428063268914135\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -0.08252150768418343\n",
      "Score on testing data: -0.09493369649272454\n",
      "Mean Absolute Error:  0.1260285747240549\n",
      "R Squared:  -0.09493369649272454\n",
      "\n",
      "\n",
      "--------------Experiment 4--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8649237259546625\n",
      "Score on testing data: 0.08472849912561053\n",
      "Mean Absolute Error:  0.08376558797461844\n",
      "R Squared:  0.08472849912561053\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.4447223704224743\n",
      "Score on testing data: 0.08614163921421547\n",
      "Mean Absolute Error:  0.07517293680894652\n",
      "R Squared:  0.08614163921421547\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999998887213692\n",
      "Score on testing data: -0.8284787573328365\n",
      "Mean Absolute Error:  0.08491290274813146\n",
      "R Squared:  -0.8284787573328365\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999998887213692\n",
      "Score on testing data: 0.07736823136734228\n",
      "Mean Absolute Error:  0.0854522646006278\n",
      "R Squared:  0.07736823136734228\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -0.08206320639897413\n",
      "Score on testing data: -0.0943800466559932\n",
      "Mean Absolute Error:  0.12595026822277153\n",
      "R Squared:  -0.0943800466559932\n",
      "\n",
      "____________________________________________\n",
      "\n",
      "\n",
      "____Running all experiments for Region 6____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9765735784468058\n",
      "Score on testing data: 0.8893324478579335\n",
      "Mean Absolute Error:  0.04551388776623327\n",
      "R Squared:  0.8893324478579335\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9808861642122295\n",
      "Score on testing data: 0.8812099304448696\n",
      "Mean Absolute Error:  0.0456389308954481\n",
      "R Squared:  0.8812099304448696\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.849177876148411\n",
      "Mean Absolute Error:  0.048637885610091004\n",
      "R Squared:  0.849177876148411\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.890789925807552\n",
      "Mean Absolute Error:  0.04573147330676118\n",
      "R Squared:  0.890789925807552\n",
      "\n",
      "Running SVR\n",
      "Score on training data: 0.00815431973774361\n",
      "Score on testing data: -0.01460113301781707\n",
      "Mean Absolute Error:  0.18943113290223365\n",
      "R Squared:  -0.01460113301781707\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8689062569966428\n",
      "Score on testing data: 0.14967110468240818\n",
      "Mean Absolute Error:  0.1643599280867688\n",
      "R Squared:  0.14967110468240818\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7129110184029432\n",
      "Score on testing data: 0.15831314061975987\n",
      "Mean Absolute Error:  0.16194740500488894\n",
      "R Squared:  0.15831314061975987\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.14798182380955693\n",
      "Mean Absolute Error:  0.140497845426124\n",
      "R Squared:  -0.14798182380955693\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.15025178138399775\n",
      "Mean Absolute Error:  0.16459163894075898\n",
      "R Squared:  0.15025178138399775\n",
      "\n",
      "Running SVR\n",
      "Score on training data: 0.003343114352050258\n",
      "Score on testing data: -0.015331927286815317\n",
      "Mean Absolute Error:  0.19033378823362804\n",
      "R Squared:  -0.015331927286815317\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8666487103299857\n",
      "Score on testing data: 0.1341919368399045\n",
      "Mean Absolute Error:  0.16682352882983684\n",
      "R Squared:  0.1341919368399045\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7056783157763391\n",
      "Score on testing data: 0.16910457786569988\n",
      "Mean Absolute Error:  0.16424884012774704\n",
      "R Squared:  0.16910457786569988\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.15993852413947796\n",
      "Mean Absolute Error:  0.14280032834359488\n",
      "R Squared:  -0.15993852413947796\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.12156199040839533\n",
      "Mean Absolute Error:  0.1673735900082014\n",
      "R Squared:  0.12156199040839533\n",
      "\n",
      "Running SVR\n",
      "Score on training data: 0.0023445470972263127\n",
      "Score on testing data: -0.016583029652147863\n",
      "Mean Absolute Error:  0.19050358471778114\n",
      "R Squared:  -0.016583029652147863\n",
      "\n",
      "\n",
      "--------------Experiment 4--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8756097875152601\n",
      "Score on testing data: 0.11401066463039322\n",
      "Mean Absolute Error:  0.167452021130001\n",
      "R Squared:  0.11401066463039322\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7976332442239058\n",
      "Score on testing data: 0.08151546811107657\n",
      "Mean Absolute Error:  0.16583981019460323\n",
      "R Squared:  0.08151546811107657\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.4164086422891584\n",
      "Mean Absolute Error:  0.16541682722317788\n",
      "R Squared:  -0.4164086422891584\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.11242009336773628\n",
      "Mean Absolute Error:  0.16656195711892494\n",
      "R Squared:  0.11242009336773628\n",
      "\n",
      "Running SVR\n",
      "Score on training data: 0.006840582232422343\n",
      "Score on testing data: -0.015491939575769997\n",
      "Mean Absolute Error:  0.18987630809094294\n",
      "R Squared:  -0.015491939575769997\n",
      "\n",
      "____________________________________________\n",
      "\n",
      "\n",
      "____Running all experiments for Region 8____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9801594155745204\n",
      "Score on testing data: 0.8771113915273818\n",
      "Mean Absolute Error:  0.008037698176966675\n",
      "R Squared:  0.8771113915273818\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9200963159599715\n",
      "Score on testing data: 0.8753364581929952\n",
      "Mean Absolute Error:  0.007552257142263818\n",
      "R Squared:  0.8753364581929952\n",
      "\n",
      "Running DecisionTreeRegressor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training data: 0.9999999593515394\n",
      "Score on testing data: 0.7857389973953917\n",
      "Mean Absolute Error:  0.008971682911362138\n",
      "R Squared:  0.7857389973953917\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999593515394\n",
      "Score on testing data: 0.876526794373302\n",
      "Mean Absolute Error:  0.008199328428659086\n",
      "R Squared:  0.876526794373302\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -1.0017405066900151\n",
      "Score on testing data: -1.165920730739057\n",
      "Mean Absolute Error:  0.10287845889107189\n",
      "R Squared:  -1.165920730739057\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8726509307078445\n",
      "Score on testing data: 0.0500535508593104\n",
      "Mean Absolute Error:  0.020713326609058447\n",
      "R Squared:  0.0500535508593104\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.28823817508317195\n",
      "Score on testing data: 0.024595106115973486\n",
      "Mean Absolute Error:  0.020041400989796454\n",
      "R Squared:  0.024595106115973486\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999438392281\n",
      "Score on testing data: -0.9449271514194975\n",
      "Mean Absolute Error:  0.0227791192542161\n",
      "R Squared:  -0.9449271514194975\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999438392281\n",
      "Score on testing data: 0.09197323375397448\n",
      "Mean Absolute Error:  0.020867056448565322\n",
      "R Squared:  0.09197323375397448\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -1.009195738830818\n",
      "Score on testing data: -1.1731740701059632\n",
      "Mean Absolute Error:  0.10310511798114062\n",
      "R Squared:  -1.1731740701059632\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8688856560168408\n",
      "Score on testing data: -0.002771735707682188\n",
      "Mean Absolute Error:  0.021038067040178358\n",
      "R Squared:  -0.002771735707682188\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.2862187939129106\n",
      "Score on testing data: -0.009665885700026688\n",
      "Mean Absolute Error:  0.02027814536637077\n",
      "R Squared:  -0.009665885700026688\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999438392281\n",
      "Score on testing data: -0.9514425089928482\n",
      "Mean Absolute Error:  0.021989041222788275\n",
      "R Squared:  -0.9514425089928482\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999438392281\n",
      "Score on testing data: 0.030641365010351196\n",
      "Mean Absolute Error:  0.0211621561431341\n",
      "R Squared:  0.030641365010351196\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -1.009393982786924\n",
      "Score on testing data: -1.1734739678278223\n",
      "Mean Absolute Error:  0.10311511843672097\n",
      "R Squared:  -1.1734739678278223\n",
      "\n",
      "\n",
      "--------------Experiment 4--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8717816383656609\n",
      "Score on testing data: 0.008398608398931695\n",
      "Mean Absolute Error:  0.022458490592560363\n",
      "R Squared:  0.008398608398931695\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.2637636312385293\n",
      "Score on testing data: 0.009374453165255425\n",
      "Mean Absolute Error:  0.02032676414821778\n",
      "R Squared:  0.009374453165255425\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999593515394\n",
      "Score on testing data: -0.9640019033303289\n",
      "Mean Absolute Error:  0.023051516773340847\n",
      "R Squared:  -0.9640019033303289\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999593515394\n",
      "Score on testing data: 0.01056469849646513\n",
      "Mean Absolute Error:  0.022411160068960295\n",
      "R Squared:  0.01056469849646513\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -1.0038198587075833\n",
      "Score on testing data: -1.1689703907707711\n",
      "Mean Absolute Error:  0.10295364070051378\n",
      "R Squared:  -1.1689703907707711\n",
      "\n",
      "____________________________________________\n",
      "\n",
      "\n",
      "____Running all experiments for Region 9____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9323736447863835\n",
      "Score on testing data: 0.703831523415263\n",
      "Mean Absolute Error:  0.005781268314746025\n",
      "R Squared:  0.703831523415263\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9393002582185409\n",
      "Score on testing data: 0.7296579482086705\n",
      "Mean Absolute Error:  0.00537536363835264\n",
      "R Squared:  0.7296579482086705\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999808006592\n",
      "Score on testing data: 0.06502035511056403\n",
      "Mean Absolute Error:  0.007869850634311691\n",
      "R Squared:  0.06502035511056403\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999808006592\n",
      "Score on testing data: 0.8225488722096166\n",
      "Mean Absolute Error:  0.0063132355268454374\n",
      "R Squared:  0.8225488722096166\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -1.623087752440541\n",
      "Score on testing data: -3.2579944863207944\n",
      "Mean Absolute Error:  0.10057050087007174\n",
      "R Squared:  -3.2579944863207944\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8574160571902085\n",
      "Score on testing data: 0.10770934451566261\n",
      "Mean Absolute Error:  0.010537015996524676\n",
      "R Squared:  0.10770934451566261\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7649986606878914\n",
      "Score on testing data: -0.13811321427403622\n",
      "Mean Absolute Error:  0.011471518759670929\n",
      "R Squared:  -0.13811321427403622\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999808006592\n",
      "Score on testing data: -1.2380829238615663\n",
      "Mean Absolute Error:  0.012352985396288237\n",
      "R Squared:  -1.2380829238615663\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999808006592\n",
      "Score on testing data: 0.20245397695431122\n",
      "Mean Absolute Error:  0.01080416693242864\n",
      "R Squared:  0.20245397695431122\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -1.629118669056154\n",
      "Score on testing data: -3.2685441388522802\n",
      "Mean Absolute Error:  0.10072321274967966\n",
      "R Squared:  -3.2685441388522802\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8600206527734394\n",
      "Score on testing data: 0.09554776521101882\n",
      "Mean Absolute Error:  0.01084000280007224\n",
      "R Squared:  0.09554776521101882\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7732767849845333\n",
      "Score on testing data: 0.1100108888110739\n",
      "Mean Absolute Error:  0.010259479384902638\n",
      "R Squared:  0.1100108888110739\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999808006592\n",
      "Score on testing data: -0.27216484074617076\n",
      "Mean Absolute Error:  0.008544353802940463\n",
      "R Squared:  -0.27216484074617076\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999808006592\n",
      "Score on testing data: 0.22500391365522343\n",
      "Mean Absolute Error:  0.01068181954697091\n",
      "R Squared:  0.22500391365522343\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -1.6288913565298957\n",
      "Score on testing data: -3.266688878721414\n",
      "Mean Absolute Error:  0.10070628051759324\n",
      "R Squared:  -3.266688878721414\n",
      "\n",
      "\n",
      "--------------Experiment 4--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8553404928980931\n",
      "Score on testing data: -0.02596071256270638\n",
      "Mean Absolute Error:  0.013402825137741051\n",
      "R Squared:  -0.02596071256270638\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7447882090914624\n",
      "Score on testing data: -0.21298472178987615\n",
      "Mean Absolute Error:  0.014267514763647298\n",
      "R Squared:  -0.21298472178987615\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999808006592\n",
      "Score on testing data: -1.223745156248917\n",
      "Mean Absolute Error:  0.011753462269018633\n",
      "R Squared:  -1.223745156248917\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999808006592\n",
      "Score on testing data: 0.10600591832298356\n",
      "Mean Absolute Error:  0.013794599952936965\n",
      "R Squared:  0.10600591832298356\n",
      "\n",
      "Running SVR\n",
      "Score on training data: -1.570461568385014\n",
      "Score on testing data: -3.15946839644264\n",
      "Mean Absolute Error:  0.09912530198299538\n",
      "R Squared:  -3.15946839644264\n",
      "\n",
      "____________________________________________\n",
      "\n",
      "\n",
      "____Running all experiments for Region 10____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9652043605470396\n",
      "Score on testing data: 0.8748006357206894\n",
      "Mean Absolute Error:  0.09717100517548115\n",
      "R Squared:  0.8748006357206894\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9831821965718232\n",
      "Score on testing data: 0.8879568763018986\n",
      "Mean Absolute Error:  0.08955747504070288\n",
      "R Squared:  0.8879568763018986\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.8679540331519928\n",
      "Mean Absolute Error:  0.07953663270257155\n",
      "R Squared:  0.8679540331519928\n",
      "\n",
      "Running ExtraTreesRegressor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training data: 1.0\n",
      "Score on testing data: 0.8594937127282372\n",
      "Mean Absolute Error:  0.10701534449296464\n",
      "R Squared:  0.8594937127282372\n",
      "\n",
      "Running SVR\n",
      "Score on training data: 0.22517469511566346\n",
      "Score on testing data: 0.11264268632147412\n",
      "Mean Absolute Error:  0.32332386597499285\n",
      "R Squared:  0.11264268632147412\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8964035012003645\n",
      "Score on testing data: 0.18863396938046073\n",
      "Mean Absolute Error:  0.29272049975739933\n",
      "R Squared:  0.18863396938046073\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9225220625042893\n",
      "Score on testing data: -0.0046979668001838615\n",
      "Mean Absolute Error:  0.3173759119203613\n",
      "R Squared:  -0.0046979668001838615\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.545343964976077\n",
      "Mean Absolute Error:  0.31994703218502346\n",
      "R Squared:  -0.545343964976077\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.14208728483065824\n",
      "Mean Absolute Error:  0.2919616893093968\n",
      "R Squared:  0.14208728483065824\n",
      "\n",
      "Running SVR\n",
      "Score on training data: 0.19879888550529434\n",
      "Score on testing data: -0.05948169405163517\n",
      "Mean Absolute Error:  0.3693586500701392\n",
      "R Squared:  -0.05948169405163517\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8919028641690582\n",
      "Score on testing data: 0.0860924646020641\n",
      "Mean Absolute Error:  0.3213076823548439\n",
      "R Squared:  0.0860924646020641\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9167706741821715\n",
      "Score on testing data: -0.1387360115368328\n",
      "Mean Absolute Error:  0.3509294513787042\n",
      "R Squared:  -0.1387360115368328\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.9961618818262756\n",
      "Mean Absolute Error:  0.41817119521268\n",
      "R Squared:  -0.9961618818262756\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.1458827308757623\n",
      "Mean Absolute Error:  0.3101176087659713\n",
      "R Squared:  0.1458827308757623\n",
      "\n",
      "Running SVR\n",
      "Score on training data: 0.17898659915635184\n",
      "Score on testing data: -0.08705399984129003\n",
      "Mean Absolute Error:  0.3734935991080398\n",
      "R Squared:  -0.08705399984129003\n",
      "\n",
      "\n",
      "--------------Experiment 4--------------\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9011264776879001\n",
      "Score on testing data: 0.19412815514714454\n",
      "Mean Absolute Error:  0.2864205280608119\n",
      "R Squared:  0.19412815514714454\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9542654964882553\n",
      "Score on testing data: 0.07363864454952951\n",
      "Mean Absolute Error:  0.2948118557810886\n",
      "R Squared:  0.07363864454952951\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.5655425039394195\n",
      "Mean Absolute Error:  0.3274446061782307\n",
      "R Squared:  -0.5655425039394195\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.19420253303328838\n",
      "Mean Absolute Error:  0.2813596352903122\n",
      "R Squared:  0.19420253303328838\n",
      "\n",
      "Running SVR\n",
      "Score on training data: 0.21717589687243588\n",
      "Score on testing data: 0.19753492760359403\n",
      "Mean Absolute Error:  0.3014673514012801\n",
      "R Squared:  0.19753492760359403\n",
      "\n",
      "____________________________________________\n"
     ]
    }
   ],
   "source": [
    "#regionCount=1\n",
    "regionExperimentDict = {}\n",
    "for i in range(len(dfRegionList)):\n",
    "    dfRegion = dfRegionList[i]\n",
    "    regionCount =i+1\n",
    "    if(regionCount>=7):\n",
    "        regionCount+=1\n",
    "    \n",
    "    experimentList = experimentCreation_FireSizePrediction(dfRegion,\"fire_size\")\n",
    "    print(f\"\\n\\n____Running all experiments for Region {regionCount}____\")\n",
    "    print(\"____________________________________________\")\n",
    "    print(\"____________________________________________\")\n",
    "    experimentListOfDictionaries = []\n",
    "    for i in range(len(experimentList)):\n",
    "        #if(i not in [1,2,3]):\n",
    "        experiment=experimentList[i]\n",
    "        print(f\"\\n--------------Experiment {i+1}--------------\")\n",
    "        #print(experiment[0].shape,experiment[1].shape,experiment[2].shape,experiment[3].shape)\n",
    "        regressorDict = run_all_regressors(experiment[0],experiment[2],experiment[1],experiment[3])\n",
    "        if(i not in [1,2,3]):\n",
    "            experimentListOfDictionaries.append(regressorDict)\n",
    "    print(\"____________________________________________\")\n",
    "    \n",
    "    regionExperimentDict[regionCount]= experimentListOfDictionaries\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from Region 1\n",
      "[{'RandomForestRegressor': [0.9802185520772947, 0.8679309062586006, 0.038127723630631744, 0.8679309062586006], 'GradientBoostingRegressor': [0.9743691746910226, 0.854812394338564, 0.038877218327901746, 0.854812394338564], 'DecisionTreeRegressor': [0.9999999760149556, 0.8298083336446657, 0.038144774059926764, 0.8298083336446657], 'ExtraTreesRegressor': [0.9999999760149556, 0.8599808485903878, 0.03788734458200143, 0.8599808485903878], 'SVR': [0.023669598559045824, 0.006796051146053861, 0.16133878041211616, 0.006796051146053861]}]\n",
      "Results from Region 2\n",
      "[{'RandomForestRegressor': [0.9597396807287967, 0.6404695740972389, 0.04751856221962242, 0.6404695740972389], 'GradientBoostingRegressor': [0.9051818852303684, 0.672108212602953, 0.044908979937677854, 0.672108212602953], 'DecisionTreeRegressor': [1.0, 0.2861918342799159, 0.05205152538207517, 0.2861918342799159], 'ExtraTreesRegressor': [1.0, 0.8148825110492605, 0.03486456474767063, 0.8148825110492605], 'SVR': [-0.023215636280210505, -0.04681376121657599, 0.13077681003132435, -0.04681376121657599]}]\n",
      "Results from Region 3\n",
      "[{'RandomForestRegressor': [0.9807379068090071, 0.8875269462244004, 0.03442766976846553, 0.8875269462244004], 'GradientBoostingRegressor': [0.990398266838978, 0.8702734948362223, 0.03135386501707144, 0.8702734948362223], 'DecisionTreeRegressor': [0.9999999999786066, 0.8065455868788571, 0.03869420421057478, 0.8065455868788571], 'ExtraTreesRegressor': [0.9999999999786066, 0.9054129813653979, 0.0316598159929155, 0.9054129813653979], 'SVR': [0.007271681249555018, -0.015003288967290862, 0.15552859354597787, -0.015003288967290862]}]\n",
      "Results from Region 4\n",
      "[{'RandomForestRegressor': [0.9756736154163953, 0.8092845399807367, 0.07669580378604947, 0.8092845399807367], 'GradientBoostingRegressor': [0.931085068681722, 0.7877392614764481, 0.07982949129862313, 0.7877392614764481], 'DecisionTreeRegressor': [1.0, 0.6949088070378365, 0.0832014711493552, 0.6949088070378365], 'ExtraTreesRegressor': [1.0, 0.8175055124268299, 0.07283581365858655, 0.8175055124268299], 'SVR': [-0.041617571247722474, -0.08033336420138082, 0.2309731696055511, -0.08033336420138082]}]\n",
      "Results from Region 5\n",
      "[{'RandomForestRegressor': [0.9808272672813698, 0.8796347763060499, 0.022566329767563367, 0.8796347763060499], 'GradientBoostingRegressor': [0.9540695813207151, 0.9044306453058064, 0.019805321806126437, 0.9044306453058064], 'DecisionTreeRegressor': [0.9999998887213692, 0.7374743493087104, 0.027559920511661135, 0.7374743493087104], 'ExtraTreesRegressor': [0.9999998887213692, 0.8534402129562957, 0.02548071138079128, 0.8534402129562957], 'SVR': [-0.08044109200393224, -0.09296565901862852, 0.12595148640027584, -0.09296565901862852]}]\n",
      "Results from Region 6\n",
      "[{'RandomForestRegressor': [0.9765735784468058, 0.8893324478579335, 0.04551388776623327, 0.8893324478579335], 'GradientBoostingRegressor': [0.9808861642122295, 0.8812099304448696, 0.0456389308954481, 0.8812099304448696], 'DecisionTreeRegressor': [1.0, 0.849177876148411, 0.048637885610091004, 0.849177876148411], 'ExtraTreesRegressor': [1.0, 0.890789925807552, 0.04573147330676118, 0.890789925807552], 'SVR': [0.00815431973774361, -0.01460113301781707, 0.18943113290223365, -0.01460113301781707]}]\n",
      "Results from Region 8\n",
      "[{'RandomForestRegressor': [0.9801594155745204, 0.8771113915273818, 0.008037698176966675, 0.8771113915273818], 'GradientBoostingRegressor': [0.9200963159599715, 0.8753364581929952, 0.007552257142263818, 0.8753364581929952], 'DecisionTreeRegressor': [0.9999999593515394, 0.7857389973953917, 0.008971682911362138, 0.7857389973953917], 'ExtraTreesRegressor': [0.9999999593515394, 0.876526794373302, 0.008199328428659086, 0.876526794373302], 'SVR': [-1.0017405066900151, -1.165920730739057, 0.10287845889107189, -1.165920730739057]}]\n",
      "Results from Region 9\n",
      "[{'RandomForestRegressor': [0.9323736447863835, 0.703831523415263, 0.005781268314746025, 0.703831523415263], 'GradientBoostingRegressor': [0.9393002582185409, 0.7296579482086705, 0.00537536363835264, 0.7296579482086705], 'DecisionTreeRegressor': [0.9999999808006592, 0.06502035511056403, 0.007869850634311691, 0.06502035511056403], 'ExtraTreesRegressor': [0.9999999808006592, 0.8225488722096166, 0.0063132355268454374, 0.8225488722096166], 'SVR': [-1.623087752440541, -3.2579944863207944, 0.10057050087007174, -3.2579944863207944]}]\n",
      "Results from Region 10\n",
      "[{'RandomForestRegressor': [0.9652043605470396, 0.8748006357206894, 0.09717100517548115, 0.8748006357206894], 'GradientBoostingRegressor': [0.9831821965718232, 0.8879568763018986, 0.08955747504070288, 0.8879568763018986], 'DecisionTreeRegressor': [1.0, 0.8679540331519928, 0.07953663270257155, 0.8679540331519928], 'ExtraTreesRegressor': [1.0, 0.8594937127282372, 0.10701534449296464, 0.8594937127282372], 'SVR': [0.22517469511566346, 0.11264268632147412, 0.32332386597499285, 0.11264268632147412]}]\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    regionCt = i+1\n",
    "    if(regionCt>=7):\n",
    "        regionCt+=1\n",
    "    print(f\"Results from Region {regionCt}\")\n",
    "    print(regionExperimentDict[regionCt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRegionDFResults(regressorDict):\n",
    "    dfRegressionResults = pd.DataFrame(columns=['ModelName','TrainScore','TestScore','MAE','R^2'])\n",
    "    for key in regressorDict.keys():\n",
    "        #print(key)\n",
    "        resultList = regressorDict[key]\n",
    "        new_row = {'ModelName':key, 'TrainScore':resultList[0], 'TestScore':resultList[1], 'MAE':resultList[2] , 'R^2':resultList[3]}\n",
    "        \n",
    "        dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
    "    return dfRegressionResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\2820425752.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegressionResults = dfRegressionResults.append(new_row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "regionRegressionList=[]\n",
    "for i in range(1,len(regionExperimentDict)+1):\n",
    "    \n",
    "    if(i>=7):\n",
    "        i+=1\n",
    "    #print(i)\n",
    "    regionRegressionResults = createRegionDFResults(regionExperimentDict[i][0])\n",
    "    regionRegressionList.append(regionRegressionResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Region 1\n",
      "                   ModelName  TrainScore  TestScore       MAE       R^2\n",
      "0      RandomForestRegressor    0.980219   0.867931  0.038128  0.867931\n",
      "1  GradientBoostingRegressor    0.974369   0.854812  0.038877  0.854812\n",
      "2      DecisionTreeRegressor    1.000000   0.829808  0.038145  0.829808\n",
      "3        ExtraTreesRegressor    1.000000   0.859981  0.037887  0.859981\n",
      "4                        SVR    0.023670   0.006796  0.161339  0.006796\n",
      "\n",
      "Region 2\n",
      "                   ModelName  TrainScore  TestScore       MAE       R^2\n",
      "0      RandomForestRegressor    0.959740   0.640470  0.047519  0.640470\n",
      "1  GradientBoostingRegressor    0.905182   0.672108  0.044909  0.672108\n",
      "2      DecisionTreeRegressor    1.000000   0.286192  0.052052  0.286192\n",
      "3        ExtraTreesRegressor    1.000000   0.814883  0.034865  0.814883\n",
      "4                        SVR   -0.023216  -0.046814  0.130777 -0.046814\n",
      "\n",
      "Region 3\n",
      "                   ModelName  TrainScore  TestScore       MAE       R^2\n",
      "0      RandomForestRegressor    0.980738   0.887527  0.034428  0.887527\n",
      "1  GradientBoostingRegressor    0.990398   0.870273  0.031354  0.870273\n",
      "2      DecisionTreeRegressor    1.000000   0.806546  0.038694  0.806546\n",
      "3        ExtraTreesRegressor    1.000000   0.905413  0.031660  0.905413\n",
      "4                        SVR    0.007272  -0.015003  0.155529 -0.015003\n",
      "\n",
      "Region 4\n",
      "                   ModelName  TrainScore  TestScore       MAE       R^2\n",
      "0      RandomForestRegressor    0.975674   0.809285  0.076696  0.809285\n",
      "1  GradientBoostingRegressor    0.931085   0.787739  0.079829  0.787739\n",
      "2      DecisionTreeRegressor    1.000000   0.694909  0.083201  0.694909\n",
      "3        ExtraTreesRegressor    1.000000   0.817506  0.072836  0.817506\n",
      "4                        SVR   -0.041618  -0.080333  0.230973 -0.080333\n",
      "\n",
      "Region 5\n",
      "                   ModelName  TrainScore  TestScore       MAE       R^2\n",
      "0      RandomForestRegressor    0.980827   0.879635  0.022566  0.879635\n",
      "1  GradientBoostingRegressor    0.954070   0.904431  0.019805  0.904431\n",
      "2      DecisionTreeRegressor    1.000000   0.737474  0.027560  0.737474\n",
      "3        ExtraTreesRegressor    1.000000   0.853440  0.025481  0.853440\n",
      "4                        SVR   -0.080441  -0.092966  0.125951 -0.092966\n",
      "\n",
      "Region 6\n",
      "                   ModelName  TrainScore  TestScore       MAE       R^2\n",
      "0      RandomForestRegressor    0.976574   0.889332  0.045514  0.889332\n",
      "1  GradientBoostingRegressor    0.980886   0.881210  0.045639  0.881210\n",
      "2      DecisionTreeRegressor    1.000000   0.849178  0.048638  0.849178\n",
      "3        ExtraTreesRegressor    1.000000   0.890790  0.045731  0.890790\n",
      "4                        SVR    0.008154  -0.014601  0.189431 -0.014601\n",
      "\n",
      "Region 8\n",
      "                   ModelName  TrainScore  TestScore       MAE       R^2\n",
      "0      RandomForestRegressor    0.980159   0.877111  0.008038  0.877111\n",
      "1  GradientBoostingRegressor    0.920096   0.875336  0.007552  0.875336\n",
      "2      DecisionTreeRegressor    1.000000   0.785739  0.008972  0.785739\n",
      "3        ExtraTreesRegressor    1.000000   0.876527  0.008199  0.876527\n",
      "4                        SVR   -1.001741  -1.165921  0.102878 -1.165921\n",
      "\n",
      "Region 9\n",
      "                   ModelName  TrainScore  TestScore       MAE       R^2\n",
      "0      RandomForestRegressor    0.932374   0.703832  0.005781  0.703832\n",
      "1  GradientBoostingRegressor    0.939300   0.729658  0.005375  0.729658\n",
      "2      DecisionTreeRegressor    1.000000   0.065020  0.007870  0.065020\n",
      "3        ExtraTreesRegressor    1.000000   0.822549  0.006313  0.822549\n",
      "4                        SVR   -1.623088  -3.257994  0.100571 -3.257994\n",
      "\n",
      "Region 10\n",
      "                   ModelName  TrainScore  TestScore       MAE       R^2\n",
      "0      RandomForestRegressor    0.965204   0.874801  0.097171  0.874801\n",
      "1  GradientBoostingRegressor    0.983182   0.887957  0.089557  0.887957\n",
      "2      DecisionTreeRegressor    1.000000   0.867954  0.079537  0.867954\n",
      "3        ExtraTreesRegressor    1.000000   0.859494  0.107015  0.859494\n",
      "4                        SVR    0.225175   0.112643  0.323324  0.112643\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(regionRegressionList)):\n",
    "    dfTemp = regionRegressionList[i]\n",
    "    regionNum= i+1\n",
    "    if(regionNum>=7):\n",
    "        regionNum+=1\n",
    "    print(f\"\\nRegion {regionNum}\")\n",
    "    print(dfTemp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\3316523368.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegionModelResults = dfRegionModelResults.append(row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\3316523368.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegionModelResults = dfRegionModelResults.append(row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\3316523368.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegionModelResults = dfRegionModelResults.append(row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\3316523368.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegionModelResults = dfRegionModelResults.append(row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\3316523368.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegionModelResults = dfRegionModelResults.append(row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\3316523368.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegionModelResults = dfRegionModelResults.append(row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\3316523368.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegionModelResults = dfRegionModelResults.append(row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\3316523368.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegionModelResults = dfRegionModelResults.append(row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_19188\\3316523368.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfRegionModelResults = dfRegionModelResults.append(row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"dfRegion1 size: 1027\n",
    "dfRegion2 size: 1766\n",
    "dfRegion3 size: 975\n",
    "dfRegion4 size: 1482\n",
    "dfRegion5 size: 2567\n",
    "dfRegion6 size: 832\n",
    "dfRegion8 size: 22069\n",
    "dfRegion9 size: 4293\n",
    "dfRegion10 size: 247\"\"\"\n",
    "#TODO select best model and put in region table\n",
    "dfRegionModelResults = pd.DataFrame(columns=['Region','RegionSize','ModelName','MAE','R^2'])\n",
    "r1 = {'Region':1 ,'ModelName':\"RandomForestRegressor\", 'RegionSize':1027,'MAE':0.038844   , 'R^2':0.864012}\n",
    "r2 = {'Region':2 ,'ModelName':\"ExtraTreesRegressor\", 'RegionSize':1766,'MAE':0.035026  , 'R^2':0.817728}\n",
    "r3 = {'Region':3 ,'ModelName':\"ExtraTreesRegressor\", 'RegionSize':975,'MAE':0.032393   , 'R^2':0.903682}\n",
    "r4 = {'Region':4 ,'ModelName':\"ExtraTreesRegressor\", 'RegionSize':1482,'MAE':0.075709   , 'R^2':0.811049}\n",
    "r5 = {'Region':5 ,'ModelName':\"GradientBoostingRegressor\",'RegionSize':2567, 'MAE':0.020157  , 'R^2':0.901066}\n",
    "r6 = {'Region':6 ,'ModelName':\"ExtraTreesRegressor\", 'RegionSize':832,'MAE':0.046512   , 'R^2':0.890339}\n",
    "r8 = {'Region':8 ,'ModelName':\"RandomForestRegressor\", 'RegionSize':22069,'MAE':0.007910     , 'R^2':0.888664}\n",
    "r9 = {'Region':9 ,'ModelName':\"ExtraTreesRegressor \", 'RegionSize':247,'MAE':0.006403    , 'R^2':0.877449}\n",
    "r10 = {'Region':10 ,'ModelName':\"GradientBoostingRegressor\", 'RegionSize':1027,'MAE':0.093626, 'R^2':0.879954}\n",
    "rowList = [r1,r2,r3,r4,r5,r6,r8,r9,r10]\n",
    "for row in rowList: \n",
    "    dfRegionModelResults = dfRegionModelResults.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>RegionSize</th>\n",
       "      <th>ModelName</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1027</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.038844</td>\n",
       "      <td>0.864012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1766</td>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.035026</td>\n",
       "      <td>0.817728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>975</td>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.032393</td>\n",
       "      <td>0.903682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1482</td>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.075709</td>\n",
       "      <td>0.811049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2567</td>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.020157</td>\n",
       "      <td>0.901066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>832</td>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.890339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>22069</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.007910</td>\n",
       "      <td>0.888664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>247</td>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.877449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>1027</td>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.093626</td>\n",
       "      <td>0.879954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Region RegionSize                  ModelName       MAE       R^2\n",
       "0      1       1027      RandomForestRegressor  0.038844  0.864012\n",
       "1      2       1766        ExtraTreesRegressor  0.035026  0.817728\n",
       "2      3        975        ExtraTreesRegressor  0.032393  0.903682\n",
       "3      4       1482        ExtraTreesRegressor  0.075709  0.811049\n",
       "4      5       2567  GradientBoostingRegressor  0.020157  0.901066\n",
       "5      6        832        ExtraTreesRegressor  0.046512  0.890339\n",
       "6      8      22069      RandomForestRegressor  0.007910  0.888664\n",
       "7      9        247       ExtraTreesRegressor   0.006403  0.877449\n",
       "8     10       1027  GradientBoostingRegressor  0.093626  0.879954"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfRegionModelResults.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running all Classification Models for Fire Cause Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical values to numeric\n",
    "df['stat_cause_descr'] = df['stat_cause_descr'].apply(lambda x: cause_encoded_dist[x]).astype('int')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionCount=1\n",
    "for dfRegion in dfRegionList:\n",
    "    if(regionCount>=7):\n",
    "        regionCount+=1\n",
    "    \n",
    "    experimentList = experimentCreation_FireSizePrediction(dfRegion)\n",
    "    print(f\"\\n\\n____Running all experiments for Region {regionCount}____\")\n",
    "    print(\"____________________________________________\")\n",
    "    print(\"____________________________________________\")\n",
    "    for i in range(len(experimentList)):\n",
    "        experiment=experimentList[i]\n",
    "        print(f\"\\n--------------Experiment {i+1}--------------\")\n",
    "        print(experiment[0].size,experiment[1].size,experiment[2].size,experiment[3].size)\n",
    "        run_all_regressors(experiment[0],experiment[2],experiment[1],experiment[3])\n",
    "    print(\"____________________________________________\")\n",
    "    regionCount+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter tuning: TODO Have not done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor()\n",
    "search_grid={'n_estimators':[50,100,200],'max_depth':[2,5,8,10]}\n",
    "search=GridSearchCV(estimator=rf_reg,param_grid=search_grid,scoring='neg_mean_absolute_error',n_jobs=1,cv=5, verbose=1)\n",
    "search.fit(df1[0], df1[2])\n",
    "print(search.best_score_)\n",
    "print(search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor \n",
    "rf_reg = RandomForestRegressor(n_estimators = 200, max_depth=10)\n",
    "\n",
    "# fit the regressor with x and y data\n",
    "rf_reg.fit(df1[0], df1[2])\n",
    "\n",
    "predictions = rf_reg.predict(df1[1])\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(df1[3], predictions))\n",
    "print('R Squared:', metrics.r2_score(df1[3], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network model (from other nb) will run later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting features and target variables\n",
    "X = df[['Vegetation_4','Vegetation_9','Vegetation_12','Vegetation_14','Vegetation_15','Vegetation_16','latitude','Temp_pre_30','Temp_pre_15','Temp_pre_7','Temp_cont','Wind_pre_30','Wind_pre_15','Wind_pre_7','Wind_cont','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Hum_cont','Prec_pre_30','Prec_pre_15','Prec_pre_7','Prec_cont','Cause_Debris Burning','Cause_Equipment Use','Cause_Fireworks','Cause_Lightning','Cause_Miscellaneous','Cause_Missing/Undefined','Cause_Powerline','Cause_Railroad','Cause_Smoking','Cause_Structure', 'longitude']]\n",
    "y = df['fire_size']\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #normalizer,\n",
    "    Dense(34, activation=\"relu\", kernel_regularizer = regularizers.l2(0.01), kernel_initializer='normal',input_dim = X_train.shape[1]),\n",
    "    Dense(34, activation=\"relu\", kernel_regularizer = regularizers.l2(0.01)),\n",
    "    Dense(64, activation=\"relu\", kernel_regularizer = regularizers.l2(0.01)),\n",
    "    Dense(32, activation=\"relu\", kernel_regularizer = regularizers.l2(0.01)),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['accuracy','mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    validation_split=0.15,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_mae',\n",
    "        patience=20,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc, test_mae = model.evaluate(x=X_test, y=y_test, verbose=0)\n",
    "print('Mean Absolute Error: {acc:0.3f}'.format(acc=test_mae))\n",
    "print('accuracy: {acc:0.3f}'.format(acc=test_acc))\n",
    "print('loss: {acc:0.3f}'.format(acc=test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average Fire Size: {df.fire_size.mean()}\")\n",
    "print(f\"Standard Deviation of Fire Size: {df.fire_size.std()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "df6a2a6d0a1ae49166107b0c1e3b39e060bb8c0d4d18204cd0b91feeca5995f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
