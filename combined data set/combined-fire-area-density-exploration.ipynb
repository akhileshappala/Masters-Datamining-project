{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee8e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Normalization\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras as keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import plotly.express as px\n",
    "from loadDFRegion import getDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a37058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-17.85   , -64.7    ],\n",
       "       [-16.3333 , -67.8333 ],\n",
       "       [-16.3    , -67.8833 ],\n",
       "       ...,\n",
       "       [ -0.3    , -78.4667 ],\n",
       "       [  0.6    , -77.8167 ],\n",
       "       [  4.96667, -75.3833 ]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_species_distributions\n",
    "\n",
    "data = fetch_species_distributions()\n",
    "latlon = np.vstack([data.train['dd lat'],\n",
    "                    data.train['dd long']]).T\n",
    "latlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdbcbe6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species = np.array([d.decode('ascii').startswith('micro')\n",
    "                    for d in data.train['species']], dtype='int')\n",
    "species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8048a2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'construct_grids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#from sklearn.datasets.species_distributions import construct_grids\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#from sklearn.datasets.species_distributions import construct_grids\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#from sklearn.datasets.fetch_species_distributions import construct_grids\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m xgrid, ygrid \u001b[38;5;241m=\u001b[39m \u001b[43mconstruct_grids\u001b[49m(data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'construct_grids' is not defined"
     ]
    }
   ],
   "source": [
    "#from sklearn.datasets.species_distributions import construct_grids\n",
    "#from sklearn.datasets.species_distributions import construct_grids\n",
    "#from sklearn.datasets.fetch_species_distributions import construct_grids\n",
    "xgrid, ygrid = construct_grids(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ce2697",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(df_adjusted_ByRegion.dfList)):\n",
    "   # dfTemp = df_adjusted_ByRegion.dfList[i]\n",
    "   # dfTemp.plot(kind='scatter',x='longitude',y='latitude',color='coral',alpha=0.3)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addFireSizeLabel(df): \n",
    "    df =df.copy()\n",
    "    print(df[\"fire_size\"].min(),df[\"fire_size\"].max())\n",
    "    \n",
    "    df[\"fire_size_Label\"] = df.apply(lambda row: (1 if(row[\"fire_size\"]<df[\"fire_size\"].mean()) else 2 ),  axis=1)\n",
    "    #print(df[\"fire_size_Label\"])\n",
    "    return df\n",
    "#addFireSizeLabel(df_adjusted_ByRegion.dfList[0] )     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "069bb947",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mpl_toolkits.basemap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmpl_toolkits\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasemap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Basemap\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelDensity\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#from sklearn.datasets.species_distributions import construct_grids\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mpl_toolkits.basemap'"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "from sklearn.neighbors import KernelDensity\n",
    "#from sklearn.datasets.species_distributions import construct_grids\n",
    "def densityDistributionFireSize(df,dfList):\n",
    "    for j in range(len(dfList)):\n",
    "        dfTemp = addFireSizeLabel(dfList[j])\n",
    "        print(dfTemp)\n",
    "        print(\"sizeof region:\", dfTemp.shape)\n",
    "        regionNum = j+1\n",
    "        if(j>=7):\n",
    "            regionNum+=1\n",
    "        print(f\"For region {regionNum}\")\n",
    "        \n",
    "        #creating plots\n",
    "        fig, ax = plt.subplots(1, 2)\n",
    "        fig.subplots_adjust(left=0.05, right=0.95, wspace=0.05)\n",
    "        fireSize = ['SmallFire', 'LargeFire']\n",
    "        cmaps = ['Purples', 'Reds']\n",
    "        \n",
    "        x = dfTemp[[\"latitude\",\"longitude\"]]\n",
    "        print(\"____________x below\")\n",
    "        print(x)\n",
    "        print(x[\"latitude\"].min(),x[\"latitude\"].max())\n",
    "        print(x[\"longitude\"].min(),x[\"longitude\"].max())\n",
    "        print(\"size of x: \",x.shape)\n",
    "        y = dfTemp[\"fire_size_Label\"]\n",
    "        print(\"size of y: \",y.size)\n",
    "        for i, axi in enumerate(ax):\n",
    "            axi.set_title(fireSize[i])\n",
    "            # plot coastlines with basemap\n",
    "            m = Basemap(projection='cyl', llcrnrlat=x[\"latitude\"].min(),\n",
    "                        urcrnrlat=x[\"latitude\"].max(), llcrnrlon=x[\"longitude\"].min(),\n",
    "                        urcrnrlon=x[\"longitude\"].max(), resolution='c', ax=axi)\n",
    "            m.drawmapboundary(fill_color='#DDEEFF')\n",
    "            m.drawcoastlines()\n",
    "            m.drawcountries()\n",
    "\n",
    "\n",
    "            #kernel\n",
    "            # construct a spherical kernel density estimate of the distribution\n",
    "            x =x.to_numpy()\n",
    "            #y=y.to_numpy()\n",
    "            \n",
    "            kde = KernelDensity(bandwidth=0.03, metric='haversine')\n",
    "            #boolList = np.array([True if ele==i+1 else False for ele in y ])\n",
    "            #x_i = x[boolList]\n",
    "            #print(\"ylist; \", boolList)\n",
    "            #print(\"combo, \", x_i)\n",
    "            #kde.fit(np.radians(x[boolList]))\n",
    "        \n",
    "        \n",
    "        break\n",
    "df,dfRegionList = getDF()\n",
    "densityDistributionFireSize(df,dfRegionList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b16f95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
