{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Normalization\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras as keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from utils import run_all_regressors\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre-processing and EDA(Exploratory data analysis)\n",
    "Data Cleaning and filtering data which has firesize <5000 as number of small fires are high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def akReadDf():\n",
    "    # Reading the combined CSV files\n",
    "    df = pd.read_csv('Wildfire.csv')\n",
    "    df = df.drop(columns=['Unnamed: 0', 'Unnamed: 0.1','disc_date_final','cont_date_final','cont_clean_date','putout_time'])\n",
    "    df['disc_clean_date'] = pd.to_datetime(df['disc_clean_date'], format='%m/%d/%Y')\n",
    "\n",
    "    #Get rid of outliers - fires of size larger than 5000 acres, and there are large number of small fires and other very less number are having the high \n",
    "    # area of fires, because of which the deviation is very high\n",
    "    df = df.loc[df['fire_size'] < 5000]\n",
    "    df.columns\n",
    "\n",
    "    ################\n",
    "    df['Vegetation'] = df['Vegetation'].astype('category')\n",
    "    df['Cause'] = df['stat_cause_descr'].astype('category')\n",
    "\n",
    "    df = pd.get_dummies(df,prefix=['Vegetation'], columns = ['Vegetation'], drop_first=True)\n",
    "    df = pd.get_dummies(df,prefix=['Cause'], columns = ['stat_cause_descr'], drop_first=True)\n",
    "\n",
    "    ################\n",
    "    df_numerics_only = df.select_dtypes(include=np.number)\n",
    "\n",
    "    corr = df_numerics_only.corr()\n",
    "    ax = sns.heatmap(\n",
    "        corr, \n",
    "        vmin=-1, vmax=1, center=0,\n",
    "        cmap=sns.diverging_palette(220, 20, n=200),\n",
    "        square=True\n",
    "    )\n",
    "    ax.set_xticklabels(\n",
    "        ax.get_xticklabels(),\n",
    "        rotation=45,\n",
    "        horizontalalignment='right'\n",
    "    );\n",
    "    sns.set(rc={'figure.figsize':(15,15)})\n",
    "\n",
    "    ################\n",
    "    #Dealing with missing data\n",
    "    print(len(df))\n",
    "\n",
    "    # drop columns where weather_file is missing in the data, as it wont have the weather situation at that time, so its where ever data is \n",
    "    #missing we can remove those rows as it wont be useful\n",
    "    index = df[df['weather_file'] == 'File Not Found'].index\n",
    "    df.drop(index, inplace = True)\n",
    "    print(len(df))\n",
    "\n",
    "\n",
    "    ################\n",
    "    # Weather data has a lot of 0 and values some of which may be missing values,\n",
    "    # Mark '0' values in weather columns as Na (to see how many there are) \n",
    "    # As 0 wont add any value to the data, we are converting to NA and then removing them which will make data set\n",
    "    subset0 = ['Temp_pre_30','Temp_pre_15','Temp_pre_7','Temp_cont','Wind_pre_30','Wind_pre_15','Wind_pre_7','Wind_cont','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Hum_cont']\n",
    "    df[subset0] = df[subset0].replace({0:np.nan, '0':np.nan})\n",
    "    print(len(df))\n",
    "\n",
    "    # Mark '-1' as missing\n",
    "    subset_neg1 = ['Temp_pre_30','Temp_pre_15','Temp_pre_7','Temp_cont','Wind_pre_30','Wind_pre_15','Wind_pre_7','Wind_cont','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Hum_cont','Prec_pre_30','Prec_pre_15','Prec_pre_7','Prec_cont']\n",
    "    df[subset_neg1] = df[subset_neg1].replace({-1:np.nan})\n",
    "\n",
    "    # Drop observations where all weather columns are 0\n",
    "    df = df.dropna(how='all',\n",
    "                        subset=['Temp_pre_30','Temp_pre_15','Temp_pre_7','Temp_cont','Wind_pre_30','Wind_pre_15','Wind_pre_7','Wind_cont',])\n",
    "    print(len(df))\n",
    "    # This leaves us with 38,689 observations  +/- 3,000  to work with (originally we had 50,000)\n",
    "\n",
    "    ################\n",
    "    # fill the 'pre' columns temp wind and humidity with mean values\n",
    "    subset_fill_mean = ['Temp_pre_30','Temp_pre_15','Temp_pre_7', 'Wind_pre_30','Wind_pre_15','Wind_pre_7', 'Hum_pre_30', 'Hum_pre_15','Hum_pre_7']\n",
    "    df[subset_fill_mean] = df[subset_fill_mean].fillna(df[subset_fill_mean].mean())\n",
    "\n",
    "    # Fill NAs in the date of fire containment based on mean values from previous days\n",
    "    for col in ['Temp','Wind','Hum']:\n",
    "        df[f'{col}_cont'] = df.apply(\n",
    "            lambda row: (row[f'{col}_pre_7']+row[f'{col}_pre_15']+row[f'{col}_pre_30'])/3 if np.isnan(row[f'{col}_cont']) else row[f'{col}_cont'],\n",
    "            axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing region 1 dataframe...\n",
      "Grabbing region 2 dataframe...\n",
      "Grabbing region 3 dataframe...\n",
      "Grabbing region 4 dataframe...\n",
      "Grabbing region 5 dataframe...\n",
      "Grabbing region 6 dataframe...\n",
      "Grabbing region 8 dataframe...\n",
      "Grabbing region 9 dataframe...\n",
      "Grabbing region 10 dataframe...\n"
     ]
    }
   ],
   "source": [
    "from loadDFRegion import getDF\n",
    "df,dfRegionList = getDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1445578 1445578\n"
     ]
    }
   ],
   "source": [
    "#Sanity Check !!\n",
    "sum1=0\n",
    "ct=1\n",
    "for dftemp in dfRegionList:\n",
    "    if(ct>=7):\n",
    "        ct+=1\n",
    "    #print(ct, dftemp.size)\n",
    "    sum1+= dftemp.size\n",
    "print(df.size, sum1)\n",
    "assert(sum1==df.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experimentCreation_FireSizePrediction(df):\n",
    "    # Experiment 1 \n",
    "    \"\"\"\n",
    "    - which will select all teh available  features from the dataset\n",
    "    -Features included - variables related to Vegetation,Temperature, Humidity, Wind, Precipitation, cause of  fire, longitude and latitude\n",
    "    - we have 34 variables  for x-variables  to which we are gonna target one y-variable which is fire_size\n",
    "    - selecting features and target variables\"\"\"\n",
    "    X1 = df[['Vegetation','remoteness','latitude','Temp_pre_30','Temp_pre_15','Temp_pre_7','Temp_cont','Wind_pre_30','Wind_pre_15','Wind_pre_7','Wind_cont','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Hum_cont','Prec_pre_30','Prec_pre_15','Prec_pre_7','Prec_cont','stat_cause_encoded', 'longitude']]\n",
    "    #X1 = df[['Vegetation_4','remoteness', 'Vegetation_9','Vegetation_12','Vegetation_14','Vegetation_15','Vegetation_16','latitude','Temp_pre_30','Temp_pre_15','Temp_pre_7','Temp_cont','Wind_pre_30','Wind_pre_15','Wind_pre_7','Wind_cont','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Hum_cont','Prec_pre_30','Prec_pre_15','Prec_pre_7','Prec_cont','Cause_Debris Burning','Cause_Equipment Use','Cause_Fireworks','Cause_Lightning','Cause_Miscellaneous','Cause_Missing/Undefined','Cause_Powerline','Cause_Railroad','Cause_Smoking','Cause_Structure', 'longitude']]\n",
    "    # X1 = df[['Vegetation_4','Vegetation_9','Vegetation_12','Vegetation_14','Vegetation_15','Vegetation_16','latitude','Temp_pre_30','Temp_pre_15','Temp_pre_7','Temp_cont','Wind_pre_30','Wind_pre_15','Wind_pre_7','Wind_cont','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Hum_cont','Prec_pre_30','Prec_pre_15','Prec_pre_7','Prec_cont','Cause_Debris Burning','Cause_Equipment Use','Cause_Fireworks','Cause_Lightning','Cause_Miscellaneous','Cause_Missing/Undefined','Cause_Powerline','Cause_Railroad','Cause_Smoking','Cause_Structure', 'longitude']]\n",
    "\n",
    "    y = df['fire_size']\n",
    "\n",
    "    #train test split\n",
    "    X1_train, X1_test, y_train, y_test = train_test_split(X1, y, test_size=0.2, random_state=42)\n",
    "    df1 = [X1_train, X1_test, y_train, y_test]\n",
    "    #######################\n",
    "    #Experiment type 2 \n",
    "    \"\"\"-Include only long, lat, vegetation, cause and pre- weather data, without cont\n",
    "    - which is the data set where I removed the variables  on which the fire is  containining on the day\n",
    "    - removed 4 variables\n",
    "    - selecting features and target variables\"\"\"\n",
    "    X2 = df[['Vegetation','latitude','Temp_pre_30','Temp_pre_15','Temp_pre_7','Wind_pre_30','Wind_pre_15','Wind_pre_7','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Prec_pre_30','Prec_pre_15','Prec_pre_7','stat_cause_encoded', 'longitude']]\n",
    "    #X2 = df[['Vegetation_4','Vegetation_9','Vegetation_12','Vegetation_14','Vegetation_15','Vegetation_16','latitude','Temp_pre_30','Temp_pre_15','Temp_pre_7','Wind_pre_30','Wind_pre_15','Wind_pre_7','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Prec_pre_30','Prec_pre_15','Prec_pre_7','Cause_Debris Burning','Cause_Equipment Use','Cause_Fireworks','Cause_Lightning','Cause_Miscellaneous','Cause_Missing/Undefined','Cause_Powerline','Cause_Railroad','Cause_Smoking','Cause_Structure', 'longitude']]\n",
    "    y = df['fire_size']\n",
    "\n",
    "    #train test split\n",
    "    X2_train, X2_test, y_train, y_test = train_test_split(X2, y, test_size=0.2, random_state=42)\n",
    "    df2 = [X2_train, X2_test, y_train, y_test]\n",
    "    ########################\n",
    "    #Experiment 3 \n",
    "    #- Including only lat, long and weather pre- data\n",
    "    #When I have done the feature importance, I got to know that the cause and vegetation is not that important, so here we removed the 2 \n",
    "    #  selecting features and target variables\n",
    "    X3 = df[['latitude','longitude','Temp_pre_30','Temp_pre_15','Temp_pre_7','Wind_pre_30','Wind_pre_15','Wind_pre_7','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Prec_pre_30','Prec_pre_15','Prec_pre_7']]\n",
    "    y = df['fire_size']\n",
    "\n",
    "    #train test split\n",
    "    X3_train, X3_test, y_train, y_test = train_test_split(X3, y, test_size=0.2, random_state=42)\n",
    "    df3 = [X3_train, X3_test, y_train, y_test]\n",
    "    ########################\n",
    "    #Experiment 4 \n",
    "    #with experiment 1 data with normalization\n",
    "    # have done the minMax normalization for the experiment 1 data frame.\n",
    "    df_4 = df[['Vegetation','latitude','Temp_pre_30','Temp_pre_15','Temp_pre_7','Temp_cont','Wind_pre_30','Wind_pre_15','Wind_pre_7','Wind_cont','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Hum_cont','Prec_pre_30','Prec_pre_15','Prec_pre_7','Prec_cont','stat_cause_encoded', 'longitude']]\n",
    "    names = df_4.columns\n",
    "\n",
    "    # normalizing data\n",
    "    df_4 = preprocessing.normalize(df_4)\n",
    "    scaled_df = pd.DataFrame(df_4, columns=names)\n",
    "\n",
    "    #train test split\n",
    "    X4_train, X4_test, y_train, y_test = train_test_split(scaled_df, y, test_size=0.2, random_state=42)\n",
    "    df4 = [X4_train, X4_test, y_train, y_test]\n",
    "    \n",
    "    return [df1,df2,df3,df4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "\n",
      "____Running all experiments for Region 1____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 0--------------\n",
      "17241 4326 821 206\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9836127690527706\n",
      "Score on testing data: 0.8655534439732597\n",
      "Mean Absolute Error:  0.03913803430871973\n",
      "R Squared:  0.8655534439732597\n",
      "Adjusted R Squared:  0.8648974547361404\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9743691746910226\n",
      "Score on testing data: 0.8503643940062902\n",
      "Mean Absolute Error:  0.03900419407691612\n",
      "R Squared:  0.8503643940062902\n",
      "Adjusted R Squared:  0.8496342946276034\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999760149556\n",
      "Score on testing data: 0.8425040118981253\n",
      "Mean Absolute Error:  0.03569915983647213\n",
      "R Squared:  0.8425040118981253\n",
      "Adjusted R Squared:  0.841735560283316\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999760149556\n",
      "Score on testing data: 0.8622088204285812\n",
      "Mean Absolute Error:  0.03849026101496516\n",
      "R Squared:  0.8622088204285812\n",
      "Adjusted R Squared:  0.8615365121639437\n",
      "\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "13136 3296 821 206\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8689847323926958\n",
      "Score on testing data: 0.1069895255518255\n",
      "Mean Absolute Error:  0.13970479891964344\n",
      "R Squared:  0.1069895255518255\n",
      "Adjusted R Squared:  0.10263204839684814\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.6883956022728843\n",
      "Score on testing data: 0.12189265690067574\n",
      "Mean Absolute Error:  0.1316340535521194\n",
      "R Squared:  0.12189265690067574\n",
      "Adjusted R Squared:  0.1176079001182454\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999760149556\n",
      "Score on testing data: -1.016108562111691\n",
      "Mean Absolute Error:  0.17131114059872302\n",
      "R Squared:  -1.016108562111691\n",
      "Adjusted R Squared:  -1.0259462373156518\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999760149556\n",
      "Score on testing data: 0.15154775952577948\n",
      "Mean Absolute Error:  0.1332392767027248\n",
      "R Squared:  0.15154775952577948\n",
      "Adjusted R Squared:  0.14740770589735996\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "11494 2884 821 206\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8714048523236033\n",
      "Score on testing data: 0.12214443204936087\n",
      "Mean Absolute Error:  0.14250727189140727\n",
      "R Squared:  0.12214443204936087\n",
      "Adjusted R Squared:  0.11786071718309776\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.6794504053863664\n",
      "Score on testing data: 0.09643691064576365\n",
      "Mean Absolute Error:  0.1384497727216193\n",
      "R Squared:  0.09643691064576365\n",
      "Adjusted R Squared:  0.09202774952657244\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999760149556\n",
      "Score on testing data: -0.5766953769722731\n",
      "Mean Absolute Error:  0.1461205992754139\n",
      "R Squared:  -0.5766953769722731\n",
      "Adjusted R Squared:  -0.5843892547267562\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999760149556\n",
      "Score on testing data: 0.1399675809050992\n",
      "Mean Absolute Error:  0.13753978298946035\n",
      "R Squared:  0.1399675809050992\n",
      "Adjusted R Squared:  0.13577083853238092\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "16420 4120 821 206\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8786459464753528\n",
      "Score on testing data: 0.1934672828960321\n",
      "Mean Absolute Error:  0.1321249396533883\n",
      "R Squared:  0.1934672828960321\n",
      "Adjusted R Squared:  0.18953201713802292\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7176392527696083\n",
      "Score on testing data: 0.2087788655251267\n",
      "Mean Absolute Error:  0.12467166208176225\n",
      "R Squared:  0.2087788655251267\n",
      "Adjusted R Squared:  0.2049183086357641\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999760149556\n",
      "Score on testing data: -0.6903862282787723\n",
      "Mean Absolute Error:  0.14933297894709\n",
      "R Squared:  -0.6903862282787723\n",
      "Adjusted R Squared:  -0.6986340264162632\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999760149556\n",
      "Score on testing data: 0.19087436555770998\n",
      "Mean Absolute Error:  0.12985973155458455\n",
      "R Squared:  0.19087436555770998\n",
      "Adjusted R Squared:  0.186926448336718\n",
      "\n",
      "____________________________________________\n",
      "2\n",
      "\n",
      "\n",
      "____Running all experiments for Region 2____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 0--------------\n",
      "29652 7434 1412 354\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9589065324822946\n",
      "Score on testing data: 0.6489951352485623\n",
      "Mean Absolute Error:  0.046192396245996636\n",
      "R Squared:  0.6489951352485623\n",
      "Adjusted R Squared:  0.6480006530359639\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9051818852303684\n",
      "Score on testing data: 0.6720167171989204\n",
      "Mean Absolute Error:  0.045080609872509864\n",
      "R Squared:  0.6720167171989204\n",
      "Adjusted R Squared:  0.6710874607311893\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.3331256034874944\n",
      "Mean Absolute Error:  0.05068464619238171\n",
      "R Squared:  0.3331256034874944\n",
      "Adjusted R Squared:  0.33123618601221605\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.7959279004909414\n",
      "Mean Absolute Error:  0.03676384293199218\n",
      "R Squared:  0.7959279004909414\n",
      "Adjusted R Squared:  0.7953497145641079\n",
      "\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "22592 5664 1412 354\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8755626685269611\n",
      "Score on testing data: 0.023533589592193094\n",
      "Mean Absolute Error:  0.0985666903146201\n",
      "R Squared:  0.023533589592193094\n",
      "Adjusted R Squared:  0.020766905943082947\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.5574297505877059\n",
      "Score on testing data: 0.001258122765164904\n",
      "Mean Absolute Error:  0.09903861856241843\n",
      "R Squared:  0.001258122765164904\n",
      "Adjusted R Squared:  -0.0015716753640644399\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.961224520664322\n",
      "Mean Absolute Error:  0.10054370688472443\n",
      "R Squared:  -0.961224520664322\n",
      "Adjusted R Squared:  -0.9667813813568364\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.0020262282309766455\n",
      "Mean Absolute Error:  0.09818047910060448\n",
      "R Squared:  -0.0020262282309766455\n",
      "Adjusted R Squared:  -0.004865332118296539\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "19768 4956 1412 354\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.866145550538536\n",
      "Score on testing data: -0.016949466736627894\n",
      "Mean Absolute Error:  0.10438735298789037\n",
      "R Squared:  -0.016949466736627894\n",
      "Adjusted R Squared:  -0.019830926468324517\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.5303965631544489\n",
      "Score on testing data: -0.05854345161119201\n",
      "Mean Absolute Error:  0.10185514441687572\n",
      "R Squared:  -0.05854345161119201\n",
      "Adjusted R Squared:  -0.0615427651757654\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -1.16264198450299\n",
      "Mean Absolute Error:  0.10919566770815503\n",
      "R Squared:  -1.16264198450299\n",
      "Adjusted R Squared:  -1.1687696889723367\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.037883248984082796\n",
      "Mean Absolute Error:  0.101310127280816\n",
      "R Squared:  -0.037883248984082796\n",
      "Adjusted R Squared:  -0.04082402321718881\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "28240 7080 1412 354\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8796114175794293\n",
      "Score on testing data: 0.15794636972494958\n",
      "Mean Absolute Error:  0.08987196794824191\n",
      "R Squared:  0.15794636972494958\n",
      "Adjusted R Squared:  0.1555606107498113\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.6143274460690014\n",
      "Score on testing data: 0.09714743822639194\n",
      "Mean Absolute Error:  0.08999239323785357\n",
      "R Squared:  0.09714743822639194\n",
      "Adjusted R Squared:  0.09458941991849101\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -1.0235253779382778\n",
      "Mean Absolute Error:  0.10280579429529062\n",
      "R Squared:  -1.0235253779382778\n",
      "Adjusted R Squared:  -1.0292585565129717\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.1258399089844343\n",
      "Mean Absolute Error:  0.08944327301245515\n",
      "R Squared:  0.1258399089844343\n",
      "Adjusted R Squared:  0.12336318397801527\n",
      "\n",
      "____________________________________________\n",
      "3\n",
      "\n",
      "\n",
      "____Running all experiments for Region 3____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 0--------------\n",
      "16380 4095 780 195\n",
      "Running RandomForestRegressor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training data: 0.9813208613842911\n",
      "Score on testing data: 0.8936790468332427\n",
      "Mean Absolute Error:  0.03252719504276793\n",
      "R Squared:  0.8936790468332427\n",
      "Adjusted R Squared:  0.8931308661270061\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.990398266838978\n",
      "Score on testing data: 0.871041680108805\n",
      "Mean Absolute Error:  0.03141492051100504\n",
      "R Squared:  0.871041680108805\n",
      "Adjusted R Squared:  0.8703767832962062\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999999786066\n",
      "Score on testing data: 0.8028411949667318\n",
      "Mean Absolute Error:  0.03860721022286248\n",
      "R Squared:  0.8028411949667318\n",
      "Adjusted R Squared:  0.8018246629496194\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999999786066\n",
      "Score on testing data: 0.9044855930159346\n",
      "Mean Absolute Error:  0.0317085447542132\n",
      "R Squared:  0.9044855930159346\n",
      "Adjusted R Squared:  0.9039931298323682\n",
      "\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "12480 3120 780 195\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8678237649084177\n",
      "Score on testing data: 0.10146579421645463\n",
      "Mean Absolute Error:  0.1225648478646731\n",
      "R Squared:  0.10146579421645463\n",
      "Adjusted R Squared:  0.0968326819726465\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7094337974643848\n",
      "Score on testing data: -0.004827130288014736\n",
      "Mean Absolute Error:  0.1298444147024415\n",
      "R Squared:  -0.004827130288014736\n",
      "Adjusted R Squared:  -0.010008320776125679\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999999786066\n",
      "Score on testing data: -0.5427208889898889\n",
      "Mean Absolute Error:  0.12808057797555616\n",
      "R Squared:  -0.5427208889898889\n",
      "Adjusted R Squared:  -0.5506756212566755\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999999786066\n",
      "Score on testing data: 0.17042337820401599\n",
      "Mean Absolute Error:  0.11554021262136405\n",
      "R Squared:  0.17042337820401599\n",
      "Adjusted R Squared:  0.16614583197496802\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "10920 2730 780 195\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8667686528623679\n",
      "Score on testing data: 0.07266715329978057\n",
      "Mean Absolute Error:  0.12829470343930488\n",
      "R Squared:  0.07266715329978057\n",
      "Adjusted R Squared:  0.06788532646596734\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7209561116349057\n",
      "Score on testing data: 0.018675017314229714\n",
      "Mean Absolute Error:  0.13230526956535746\n",
      "R Squared:  0.018675017314229714\n",
      "Adjusted R Squared:  0.01361477799282984\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999999786066\n",
      "Score on testing data: -0.6423180187992388\n",
      "Mean Absolute Error:  0.13558873263409243\n",
      "R Squared:  -0.6423180187992388\n",
      "Adjusted R Squared:  -0.6507866936659752\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999999786066\n",
      "Score on testing data: 0.10299054501766214\n",
      "Mean Absolute Error:  0.12613548851070902\n",
      "R Squared:  0.10299054501766214\n",
      "Adjusted R Squared:  0.09836508189804782\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "15600 3900 780 195\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8566335918273812\n",
      "Score on testing data: -0.06464387147305484\n",
      "Mean Absolute Error:  0.12794205837943412\n",
      "R Squared:  -0.06464387147305484\n",
      "Adjusted R Squared:  -0.07013314124089742\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.739281307889782\n",
      "Score on testing data: -0.07380943738339907\n",
      "Mean Absolute Error:  0.1295883205784186\n",
      "R Squared:  -0.07380943738339907\n",
      "Adjusted R Squared:  -0.07934596451607967\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999999786066\n",
      "Score on testing data: -0.9592994237047907\n",
      "Mean Absolute Error:  0.14569639797200404\n",
      "R Squared:  -0.9592994237047907\n",
      "Adjusted R Squared:  -0.9694015089004844\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999999786066\n",
      "Score on testing data: 0.023094920132785135\n",
      "Mean Absolute Error:  0.12812525171110103\n",
      "R Squared:  0.023094920132785135\n",
      "Adjusted R Squared:  0.018058028769716183\n",
      "\n",
      "____________________________________________\n",
      "4\n",
      "\n",
      "\n",
      "____Running all experiments for Region 4____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 0--------------\n",
      "24885 6237 1185 297\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9779500170492009\n",
      "Score on testing data: 0.8058150904134382\n",
      "Mean Absolute Error:  0.0770799616302352\n",
      "R Squared:  0.8058150904134382\n",
      "Adjusted R Squared:  0.8051589547575544\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.931085068681722\n",
      "Score on testing data: 0.7879680265839634\n",
      "Mean Absolute Error:  0.08030107337762665\n",
      "R Squared:  0.7879680265839634\n",
      "Adjusted R Squared:  0.7872515870921313\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.7195244211453387\n",
      "Mean Absolute Error:  0.08015810192248267\n",
      "R Squared:  0.7195244211453387\n",
      "Adjusted R Squared:  0.7185767160518635\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.8102873782366586\n",
      "Mean Absolute Error:  0.0762522088399232\n",
      "R Squared:  0.8102873782366586\n",
      "Adjusted R Squared:  0.8096463540923255\n",
      "\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "18960 4752 1185 297\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8632152862271915\n",
      "Score on testing data: 0.0479569567393372\n",
      "Mean Absolute Error:  0.24943856431884817\n",
      "R Squared:  0.0479569567393372\n",
      "Adjusted R Squared:  0.044739915832859745\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.4390461083234444\n",
      "Score on testing data: 0.04886349572019022\n",
      "Mean Absolute Error:  0.2450253022214251\n",
      "R Squared:  0.04886349572019022\n",
      "Adjusted R Squared:  0.04564951809221196\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.638030857526509\n",
      "Mean Absolute Error:  0.2577468763375185\n",
      "R Squared:  -0.638030857526509\n",
      "Adjusted R Squared:  -0.6435659142784464\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.012485739576489019\n",
      "Mean Absolute Error:  0.24754184662186698\n",
      "R Squared:  0.012485739576489019\n",
      "Adjusted R Squared:  0.009148838168510975\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "16590 4158 1185 297\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.865472309745027\n",
      "Score on testing data: 0.0719872590260191\n",
      "Mean Absolute Error:  0.24455424796493552\n",
      "R Squared:  0.0719872590260191\n",
      "Adjusted R Squared:  0.06885132410600081\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.43304141095832926\n",
      "Score on testing data: 0.06486456587622469\n",
      "Mean Absolute Error:  0.24274754788787445\n",
      "R Squared:  0.06486456587622469\n",
      "Adjusted R Squared:  0.06170456199552643\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.6975415199141501\n",
      "Mean Absolute Error:  0.2630204871327295\n",
      "R Squared:  -0.6975415199141501\n",
      "Adjusted R Squared:  -0.7032778417289698\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.03557937512484166\n",
      "Mean Absolute Error:  0.2471326578882432\n",
      "R Squared:  0.03557937512484166\n",
      "Adjusted R Squared:  0.032320410908512454\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "23700 5940 1185 297\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8679114688256178\n",
      "Score on testing data: 0.07078098148211664\n",
      "Mean Absolute Error:  0.24537556421384935\n",
      "R Squared:  0.07078098148211664\n",
      "Adjusted R Squared:  0.06764119767229104\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.4686939548210981\n",
      "Score on testing data: 0.07139596451277397\n",
      "Mean Absolute Error:  0.24328098995412106\n",
      "R Squared:  0.07139596451277397\n",
      "Adjusted R Squared:  0.0682582586993351\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.7888707095055367\n",
      "Mean Absolute Error:  0.2737786234866428\n",
      "R Squared:  -0.7888707095055367\n",
      "Adjusted R Squared:  -0.7949152126631833\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.11148413661344125\n",
      "Mean Absolute Error:  0.23671443016238627\n",
      "R Squared:  0.11148413661344125\n",
      "Adjusted R Squared:  0.10848188669491943\n",
      "\n",
      "____________________________________________\n",
      "5\n",
      "\n",
      "\n",
      "____Running all experiments for Region 5____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 0--------------\n",
      "43113 10794 2053 514\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9795766627131739\n",
      "Score on testing data: 0.8788750438760694\n",
      "Mean Absolute Error:  0.023206490605099706\n",
      "R Squared:  0.8788750438760694\n",
      "Adjusted R Squared:  0.8786389109315278\n",
      "\n",
      "Running GradientBoostingRegressor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training data: 0.9540695813207151\n",
      "Score on testing data: 0.90669821498424\n",
      "Mean Absolute Error:  0.019692297993699936\n",
      "R Squared:  0.90669821498424\n",
      "Adjusted R Squared:  0.9065163232756128\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999998887213692\n",
      "Score on testing data: 0.7394698962529198\n",
      "Mean Absolute Error:  0.027680273020273708\n",
      "R Squared:  0.7394698962529198\n",
      "Adjusted R Squared:  0.738961993154267\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999998887213692\n",
      "Score on testing data: 0.8673734243878889\n",
      "Mean Absolute Error:  0.024693136588196288\n",
      "R Squared:  0.8673734243878889\n",
      "Adjusted R Squared:  0.8671148690511034\n",
      "\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "32848 8224 2053 514\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8721512660884302\n",
      "Score on testing data: 0.07994888546908907\n",
      "Mean Absolute Error:  0.0836527786496152\n",
      "R Squared:  0.07994888546908907\n",
      "Adjusted R Squared:  0.07815519498139634\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.42807631741640495\n",
      "Score on testing data: 0.042396435756369755\n",
      "Mean Absolute Error:  0.07974782577648977\n",
      "R Squared:  0.042396435756369755\n",
      "Adjusted R Squared:  0.04052953469289977\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999998887213692\n",
      "Score on testing data: -1.1421161094798409\n",
      "Mean Absolute Error:  0.08814238483155223\n",
      "R Squared:  -1.1421161094798409\n",
      "Adjusted R Squared:  -1.146292283203696\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999998887213692\n",
      "Score on testing data: 0.07155407697005434\n",
      "Mean Absolute Error:  0.08334106853019721\n",
      "R Squared:  0.07155407697005434\n",
      "Adjusted R Squared:  0.06974402033931482\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "28742 7196 2053 514\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8620760103351828\n",
      "Score on testing data: 0.05348333269310912\n",
      "Mean Absolute Error:  0.08596048777782497\n",
      "R Squared:  0.05348333269310912\n",
      "Adjusted R Squared:  0.0516380140268653\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.4194121984285739\n",
      "Score on testing data: 0.02586276744849636\n",
      "Mean Absolute Error:  0.0806731309652874\n",
      "R Squared:  0.02586276744849636\n",
      "Adjusted R Squared:  0.023963600026727705\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999998887213692\n",
      "Score on testing data: -0.8170385685121575\n",
      "Mean Absolute Error:  0.07752628683897062\n",
      "R Squared:  -0.8170385685121575\n",
      "Adjusted R Squared:  -0.8205810472698751\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999998887213692\n",
      "Score on testing data: 0.04981241581392848\n",
      "Mean Absolute Error:  0.08507682825892267\n",
      "R Squared:  0.04981241581392848\n",
      "Adjusted R Squared:  0.04795994036780615\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "41060 10280 2053 514\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8630688068140794\n",
      "Score on testing data: 0.09622158027217376\n",
      "Mean Absolute Error:  0.0815768148133744\n",
      "R Squared:  0.09622158027217376\n",
      "Adjusted R Squared:  0.0944596572392703\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.4447223704224743\n",
      "Score on testing data: 0.08367574243078157\n",
      "Mean Absolute Error:  0.07597700802715254\n",
      "R Squared:  0.08367574243078157\n",
      "Adjusted R Squared:  0.08188936118978496\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999998887213692\n",
      "Score on testing data: -0.9468090694679931\n",
      "Mean Absolute Error:  0.08887758899576725\n",
      "R Squared:  -0.9468090694679931\n",
      "Adjusted R Squared:  -0.9506043888353155\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999998887213692\n",
      "Score on testing data: 0.05704843938827808\n",
      "Mean Absolute Error:  0.08651099717136554\n",
      "R Squared:  0.05704843938827808\n",
      "Adjusted R Squared:  0.05521014801365742\n",
      "\n",
      "____________________________________________\n",
      "6\n",
      "\n",
      "\n",
      "____Running all experiments for Region 6____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 0--------------\n",
      "13965 3507 665 167\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9729235098606578\n",
      "Score on testing data: 0.8903361645612271\n",
      "Mean Absolute Error:  0.044512519547277696\n",
      "R Squared:  0.8903361645612271\n",
      "Adjusted R Squared:  0.8896753494839776\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9808861642122295\n",
      "Score on testing data: 0.8798185853640299\n",
      "Mean Absolute Error:  0.04626496429355601\n",
      "R Squared:  0.8798185853640299\n",
      "Adjusted R Squared:  0.8790943931954918\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.8421942643320939\n",
      "Mean Absolute Error:  0.05103897053376825\n",
      "R Squared:  0.8421942643320939\n",
      "Adjusted R Squared:  0.841243354590623\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.8913021488740769\n",
      "Mean Absolute Error:  0.04594718066787808\n",
      "R Squared:  0.8913021488740769\n",
      "Adjusted R Squared:  0.8906471546492147\n",
      "\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "10640 2672 665 167\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8675915924332808\n",
      "Score on testing data: 0.15117198383810837\n",
      "Mean Absolute Error:  0.16110753276860876\n",
      "R Squared:  0.15117198383810837\n",
      "Adjusted R Squared:  0.14605663609475994\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7129110184029432\n",
      "Score on testing data: 0.16508654368833653\n",
      "Mean Absolute Error:  0.1609202108977133\n",
      "R Squared:  0.16508654368833653\n",
      "Adjusted R Squared:  0.16005505016630772\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.005087205695217256\n",
      "Mean Absolute Error:  0.1297802790679269\n",
      "R Squared:  0.005087205695217256\n",
      "Adjusted R Squared:  -0.0009085022930601649\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.13912875980773975\n",
      "Mean Absolute Error:  0.16397161232195723\n",
      "R Squared:  0.13912875980773975\n",
      "Adjusted R Squared:  0.13394083519641153\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "9310 2338 665 167\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8662983839785756\n",
      "Score on testing data: 0.13686210096017526\n",
      "Mean Absolute Error:  0.16673972110579985\n",
      "R Squared:  0.13686210096017526\n",
      "Adjusted R Squared:  0.13166023673866967\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7056783157763389\n",
      "Score on testing data: 0.16242682223317118\n",
      "Mean Absolute Error:  0.16501999531800962\n",
      "R Squared:  0.16242682223317118\n",
      "Adjusted R Squared:  0.15737902865213993\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.22477472164717427\n",
      "Mean Absolute Error:  0.14920714239007982\n",
      "R Squared:  -0.22477472164717427\n",
      "Adjusted R Squared:  -0.23215605875568057\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.11866926259665167\n",
      "Mean Absolute Error:  0.17106348820672715\n",
      "R Squared:  0.11866926259665167\n",
      "Adjusted R Squared:  0.11335775578492258\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "13300 3340 665 167\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8695704119193383\n",
      "Score on testing data: 0.13005709897652196\n",
      "Mean Absolute Error:  0.16434377740871567\n",
      "R Squared:  0.13005709897652196\n",
      "Adjusted R Squared:  0.12481490011527774\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7976332442239058\n",
      "Score on testing data: 0.08404878842841201\n",
      "Mean Absolute Error:  0.166520396307959\n",
      "R Squared:  0.08404878842841201\n",
      "Adjusted R Squared:  0.07852934756326235\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.3754377203114112\n",
      "Mean Absolute Error:  0.1670149084110057\n",
      "R Squared:  -0.3754377203114112\n",
      "Adjusted R Squared:  -0.38372598617649945\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.10167725949871476\n",
      "Mean Absolute Error:  0.16415996821282688\n",
      "R Squared:  0.10167725949871476\n",
      "Adjusted R Squared:  0.096264046238689\n",
      "\n",
      "____________________________________________\n",
      "8\n",
      "\n",
      "\n",
      "____Running all experiments for Region 8____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 0--------------\n",
      "370755 92694 17655 4414\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9805823007195683\n",
      "Score on testing data: 0.8814802296958766\n",
      "Mean Absolute Error:  0.00800182312212596\n",
      "R Squared:  0.8814802296958766\n",
      "Adjusted R Squared:  0.8814533724447502\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9200963159599715\n",
      "Score on testing data: 0.8758748743284679\n",
      "Mean Absolute Error:  0.007515082893652508\n",
      "R Squared:  0.8758748743284679\n",
      "Adjusted R Squared:  0.8758467468720722\n",
      "\n",
      "Running DecisionTreeRegressor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training data: 0.9999999593515394\n",
      "Score on testing data: 0.7666811759291966\n",
      "Mean Absolute Error:  0.008986285299454215\n",
      "R Squared:  0.7666811759291966\n",
      "Adjusted R Squared:  0.7666283045623815\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999593515394\n",
      "Score on testing data: 0.8768694000035058\n",
      "Mean Absolute Error:  0.00817466878584198\n",
      "R Squared:  0.8768694000035058\n",
      "Adjusted R Squared:  0.8768414979122601\n",
      "\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "282480 70624 17655 4414\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8693050121014044\n",
      "Score on testing data: 0.048457809740367064\n",
      "Mean Absolute Error:  0.020610359205538227\n",
      "R Squared:  0.048457809740367064\n",
      "Adjusted R Squared:  0.04824218416437376\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.28823817508317195\n",
      "Score on testing data: 0.03761456888725445\n",
      "Mean Absolute Error:  0.020006248720927555\n",
      "R Squared:  0.03761456888725445\n",
      "Adjusted R Squared:  0.03739648616319291\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999438392281\n",
      "Score on testing data: -0.9924446313929725\n",
      "Mean Absolute Error:  0.022933005405411527\n",
      "R Squared:  -0.9924446313929725\n",
      "Adjusted R Squared:  -0.9928961321521361\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999438392281\n",
      "Score on testing data: 0.0798848478259947\n",
      "Mean Absolute Error:  0.02120191833054702\n",
      "R Squared:  0.0798848478259947\n",
      "Adjusted R Squared:  0.07967634381881716\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "247170 61796 17655 4414\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8684302406177616\n",
      "Score on testing data: 0.01163189478612181\n",
      "Mean Absolute Error:  0.02077509322056195\n",
      "R Squared:  0.01163189478612181\n",
      "Adjusted R Squared:  0.011407923767960959\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.2862187939129106\n",
      "Score on testing data: -0.003915383595565647\n",
      "Mean Absolute Error:  0.02019131494776916\n",
      "R Squared:  -0.003915383595565647\n",
      "Adjusted R Squared:  -0.004142877734060191\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999438392281\n",
      "Score on testing data: -0.9834867041649848\n",
      "Mean Absolute Error:  0.022766887953255224\n",
      "R Squared:  -0.9834867041649848\n",
      "Adjusted R Squared:  -0.9839361759096685\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999438392281\n",
      "Score on testing data: 0.028827344994226456\n",
      "Mean Absolute Error:  0.0212150796325831\n",
      "R Squared:  0.028827344994226456\n",
      "Adjusted R Squared:  0.028607270583484\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "353100 88280 17655 4414\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8748354021397478\n",
      "Score on testing data: -0.0007132247602001929\n",
      "Mean Absolute Error:  0.022356328825477004\n",
      "R Squared:  -0.0007132247602001929\n",
      "Adjusted R Squared:  -0.0009399921663026944\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.2637636312385293\n",
      "Score on testing data: 0.010768088656138985\n",
      "Mean Absolute Error:  0.020283253377718042\n",
      "R Squared:  0.010768088656138985\n",
      "Adjusted R Squared:  0.010543922982078735\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999593515394\n",
      "Score on testing data: -0.975574611604098\n",
      "Mean Absolute Error:  0.02319932302951816\n",
      "R Squared:  -0.975574611604098\n",
      "Adjusted R Squared:  -0.9760222882402718\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999593515394\n",
      "Score on testing data: 0.0232444872142884\n",
      "Mean Absolute Error:  0.022028436035376592\n",
      "R Squared:  0.0232444872142884\n",
      "Adjusted R Squared:  0.023023148764320545\n",
      "\n",
      "____________________________________________\n",
      "10\n",
      "\n",
      "\n",
      "____Running all experiments for Region 10____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 0--------------\n",
      "72114 18039 3434 859\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9223594299997744\n",
      "Score on testing data: 0.6932320673225584\n",
      "Mean Absolute Error:  0.005846336192563056\n",
      "R Squared:  0.6932320673225584\n",
      "Adjusted R Squared:  0.6928745090949829\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9393002582185409\n",
      "Score on testing data: 0.726638975005147\n",
      "Mean Absolute Error:  0.005463740370609946\n",
      "R Squared:  0.726638975005147\n",
      "Adjusted R Squared:  0.7263203547284698\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999808006592\n",
      "Score on testing data: 0.05304836549145964\n",
      "Mean Absolute Error:  0.007966672579246799\n",
      "R Squared:  0.05304836549145964\n",
      "Adjusted R Squared:  0.05194463100044122\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999808006592\n",
      "Score on testing data: 0.7941822982957611\n",
      "Mean Absolute Error:  0.006525478572799149\n",
      "R Squared:  0.7941822982957611\n",
      "Adjusted R Squared:  0.7939424042104091\n",
      "\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "54944 13744 3434 859\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8585869500282614\n",
      "Score on testing data: 0.13463040695016426\n",
      "Mean Absolute Error:  0.010570332802639429\n",
      "R Squared:  0.13463040695016426\n",
      "Adjusted R Squared:  0.13362174420602513\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7649986606878914\n",
      "Score on testing data: -0.1297008720386965\n",
      "Mean Absolute Error:  0.011257883688394602\n",
      "R Squared:  -0.1297008720386965\n",
      "Adjusted R Squared:  -0.13101763563981983\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999808006592\n",
      "Score on testing data: -2.625168057984257\n",
      "Mean Absolute Error:  0.0160689317598628\n",
      "R Squared:  -2.625168057984257\n",
      "Adjusted R Squared:  -2.6293935033785707\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999808006592\n",
      "Score on testing data: 0.2503023686895949\n",
      "Mean Absolute Error:  0.010324651214084796\n",
      "R Squared:  0.2503023686895949\n",
      "Adjusted R Squared:  0.24942853157289302\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "48076 12026 3434 859\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.86435498036121\n",
      "Score on testing data: 0.07656787678607901\n",
      "Mean Absolute Error:  0.010998694721822959\n",
      "R Squared:  0.07656787678607901\n",
      "Adjusted R Squared:  0.0754915259639164\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7732767849845333\n",
      "Score on testing data: 0.11140840737387081\n",
      "Mean Absolute Error:  0.010224948295352646\n",
      "R Squared:  0.11140840737387081\n",
      "Adjusted R Squared:  0.1103726666115058\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999808006592\n",
      "Score on testing data: -0.8092273079376762\n",
      "Mean Absolute Error:  0.010852350984328641\n",
      "R Squared:  -0.8092273079376762\n",
      "Adjusted R Squared:  -0.8113361400341816\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999808006592\n",
      "Score on testing data: 0.25308258305603326\n",
      "Mean Absolute Error:  0.010424099842464575\n",
      "R Squared:  0.25308258305603326\n",
      "Adjusted R Squared:  0.25221197745806345\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "68680 17180 3434 859\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8650866347649748\n",
      "Score on testing data: -0.05134090662058344\n",
      "Mean Absolute Error:  0.013943622437243973\n",
      "R Squared:  -0.05134090662058344\n",
      "Adjusted R Squared:  -0.05256631708345494\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.7447882090914624\n",
      "Score on testing data: -0.2823540315723856\n",
      "Mean Absolute Error:  0.014522991045415417\n",
      "R Squared:  -0.2823540315723856\n",
      "Adjusted R Squared:  -0.2838487037928792\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 0.9999999808006592\n",
      "Score on testing data: -1.239188779116171\n",
      "Mean Absolute Error:  0.011796416626684758\n",
      "R Squared:  -1.239188779116171\n",
      "Adjusted R Squared:  -1.2417987083417859\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 0.9999999808006592\n",
      "Score on testing data: 0.11367878991947722\n",
      "Mean Absolute Error:  0.013515336114688583\n",
      "R Squared:  0.11367878991947722\n",
      "Adjusted R Squared:  0.11264572131398676\n",
      "\n",
      "____________________________________________\n",
      "12\n",
      "\n",
      "\n",
      "____Running all experiments for Region 12____\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "\n",
      "--------------Experiment 0--------------\n",
      "4137 1050 197 50\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9640758703267334\n",
      "Score on testing data: 0.876089297875154\n",
      "Mean Absolute Error:  0.0986954512372635\n",
      "R Squared:  0.876089297875154\n",
      "Adjusted R Squared:  0.8735580481235764\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9831821965718232\n",
      "Score on testing data: 0.8889119857329498\n",
      "Mean Absolute Error:  0.08933018813382859\n",
      "R Squared:  0.8889119857329498\n",
      "Adjusted R Squared:  0.8866426780485062\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.8729740825245862\n",
      "Mean Absolute Error:  0.07964175966359371\n",
      "R Squared:  0.8729740825245862\n",
      "Adjusted R Squared:  0.8703791951053413\n",
      "\n",
      "Running ExtraTreesRegressor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training data: 1.0\n",
      "Score on testing data: 0.8528958578198544\n",
      "Mean Absolute Error:  0.10967180980106747\n",
      "R Squared:  0.8528958578198544\n",
      "Adjusted R Squared:  0.8498908121138398\n",
      "\n",
      "\n",
      "--------------Experiment 1--------------\n",
      "3152 800 197 50\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8948778936552526\n",
      "Score on testing data: 0.18399300581328748\n",
      "Mean Absolute Error:  0.2958392851366651\n",
      "R Squared:  0.18399300581328748\n",
      "Adjusted R Squared:  0.16731853339057057\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9225220625042893\n",
      "Score on testing data: -0.030482773315901213\n",
      "Mean Absolute Error:  0.3229500812789921\n",
      "R Squared:  -0.030482773315901213\n",
      "Adjusted R Squared:  -0.05153989256628999\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.5237370860092392\n",
      "Mean Absolute Error:  0.3190182759178393\n",
      "R Squared:  -0.5237370860092392\n",
      "Adjusted R Squared:  -0.5548734760170908\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.1518331577951958\n",
      "Mean Absolute Error:  0.2916218866246159\n",
      "R Squared:  0.1518331577951958\n",
      "Adjusted R Squared:  0.13450152372715374\n",
      "\n",
      "\n",
      "--------------Experiment 2--------------\n",
      "2758 700 197 50\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.8899877550959878\n",
      "Score on testing data: 0.0732715664588297\n",
      "Mean Absolute Error:  0.32580730228044635\n",
      "R Squared:  0.0732715664588297\n",
      "Adjusted R Squared:  0.05433113132076195\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9167706741821715\n",
      "Score on testing data: -0.13766943298366474\n",
      "Mean Absolute Error:  0.35035352823318033\n",
      "R Squared:  -0.13766943298366474\n",
      "Adjusted R Squared:  -0.16092107103004616\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.9693004296556957\n",
      "Mean Absolute Error:  0.41193191007601493\n",
      "R Squared:  -0.9693004296556957\n",
      "Adjusted R Squared:  -1.0095489055902647\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.06955288108583002\n",
      "Mean Absolute Error:  0.32264551188743334\n",
      "R Squared:  0.06955288108583002\n",
      "Adjusted R Squared:  0.05053644361897103\n",
      "\n",
      "\n",
      "--------------Experiment 3--------------\n",
      "3940 1000 197 50\n",
      "Running RandomForestRegressor\n",
      "Score on training data: 0.9126589096950037\n",
      "Score on testing data: 0.1431410603068477\n",
      "Mean Absolute Error:  0.294594262493935\n",
      "R Squared:  0.1431410603068477\n",
      "Adjusted R Squared:  0.1256362811507057\n",
      "\n",
      "Running GradientBoostingRegressor\n",
      "Score on training data: 0.9542654964882553\n",
      "Score on testing data: 0.05827204082193793\n",
      "Mean Absolute Error:  0.29716311757673003\n",
      "R Squared:  0.05827204082193793\n",
      "Adjusted R Squared:  0.03903347168653315\n",
      "\n",
      "Running DecisionTreeRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: -0.6027719674356\n",
      "Mean Absolute Error:  0.33448366488759507\n",
      "R Squared:  -0.6027719674356\n",
      "Adjusted R Squared:  -0.6355150106927114\n",
      "\n",
      "Running ExtraTreesRegressor\n",
      "Score on training data: 1.0\n",
      "Score on testing data: 0.2670200387818178\n",
      "Mean Absolute Error:  0.2700448002587741\n",
      "R Squared:  0.2670200387818178\n",
      "Adjusted R Squared:  0.2520459844157671\n",
      "\n",
      "____________________________________________\n"
     ]
    }
   ],
   "source": [
    "regionCount=1\n",
    "for dfRegion in dfRegionList:\n",
    "    if(regionCount>=7):\n",
    "        regionCount+=1\n",
    "    print(regionCount)\n",
    "    \n",
    "    #if(regionCount==6):\n",
    "    experimentList = experimentCreation_FireSizePrediction(dfRegion)\n",
    "    print(f\"\\n\\n____Running all experiments for Region {regionCount}____\")\n",
    "    print(\"____________________________________________\")\n",
    "    print(\"____________________________________________\")\n",
    "    for i in range(len(experimentList)):\n",
    "        experiment=experimentList[i]\n",
    "        print(f\"\\n--------------Experiment {i+1}--------------\")\n",
    "        print(experiment[0].size,experiment[1].size,experiment[2].size,experiment[3].size)\n",
    "        run_all_regressors(experiment[0],experiment[2],experiment[1],experiment[3])\n",
    "    print(\"____________________________________________\")\n",
    "    regionCount+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling  the above experiments with different models like  decision tree,gradient bosting, random  forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree - Experiment 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m dectr \u001b[38;5;241m=\u001b[39m DecisionTreeRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m dectr\u001b[38;5;241m.\u001b[39mfit(\u001b[43mdf1\u001b[49m[\u001b[38;5;241m0\u001b[39m], df1[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m      4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m dectr\u001b[38;5;241m.\u001b[39mpredict(df1[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean Absolute Error:\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m.\u001b[39mmean_absolute_error(df1[\u001b[38;5;241m3\u001b[39m], predictions))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "dectr = DecisionTreeRegressor(random_state=0)\n",
    "dectr.fit(df1[0], df1[2])\n",
    "\n",
    "predictions = dectr.predict(df1[1])\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(df1[3], predictions))\n",
    "print('R Squared:', metrics.r2_score(df1[3], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Gradient Boosting - Experiment 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_boost = GradientBoostingRegressor()\n",
    "gr_boost.fit(df1[0], df1[2])\n",
    "\n",
    "predictions = gr_boost.predict(df1[1])\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(df1[3], predictions))\n",
    "print('R Squared:', metrics.r2_score(df1[3], predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(df1[0], df1[2])\n",
    "\n",
    "predictions = rf.predict(df1[1])\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(df1[3], predictions))\n",
    "print('R Squared:', metrics.r2_score(df1[3], predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling experirments \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# less than 5000\n",
    "for model in [DecisionTreeRegressor(), GradientBoostingRegressor(), RandomForestRegressor()]:\n",
    "    for idx,df in enumerate([df1, df2, df3, df4]):\n",
    "        model.fit(df[0], df[2])\n",
    "        print(f'{model}; Experiment {idx+1}; Mean Absolute Error:', metrics.mean_absolute_error(df[3], model.predict(df[1])))\n",
    "        print(f'{model}; Experiment {idx+1}; R Squared:', metrics.r2_score(df[3], model.predict(df[1])))\n",
    "        print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing basemodel is the Random Forest algorithm with R2 of 23%. This is the model we will use for further analysis and improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Reevaluate model after deleting least important features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor \n",
    "rf_reg = RandomForestRegressor()\n",
    "\n",
    "# fit the regressor with x and y data\n",
    "rf_reg.fit(X2_train, y2_train)\n",
    "\n",
    "predictions = rf_reg.predict(X2_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y2_test, predictions))\n",
    "print('R Squared:', metrics.r2_score(y2_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor()\n",
    "search_grid={'n_estimators':[50,100,200],'max_depth':[2,5,8,10]}\n",
    "search=GridSearchCV(estimator=rf_reg,param_grid=search_grid,scoring='neg_mean_absolute_error',n_jobs=1,cv=5, verbose=1)\n",
    "search.fit(df1[0], df1[2])\n",
    "print(search.best_score_)\n",
    "print(search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor \n",
    "rf_reg = RandomForestRegressor(n_estimators = 200, max_depth=10)\n",
    "\n",
    "# fit the regressor with x and y data\n",
    "rf_reg.fit(df1[0], df1[2])\n",
    "\n",
    "predictions = rf_reg.predict(df1[1])\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(df1[3], predictions))\n",
    "print('R Squared:', metrics.r2_score(df1[3], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting features and target variables\n",
    "X = df[['Vegetation_4','Vegetation_9','Vegetation_12','Vegetation_14','Vegetation_15','Vegetation_16','latitude','Temp_pre_30','Temp_pre_15','Temp_pre_7','Temp_cont','Wind_pre_30','Wind_pre_15','Wind_pre_7','Wind_cont','Hum_pre_30', 'Hum_pre_15','Hum_pre_7','Hum_cont','Prec_pre_30','Prec_pre_15','Prec_pre_7','Prec_cont','Cause_Debris Burning','Cause_Equipment Use','Cause_Fireworks','Cause_Lightning','Cause_Miscellaneous','Cause_Missing/Undefined','Cause_Powerline','Cause_Railroad','Cause_Smoking','Cause_Structure', 'longitude']]\n",
    "y = df['fire_size']\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #normalizer,\n",
    "    Dense(34, activation=\"relu\", kernel_regularizer = regularizers.l2(0.01), kernel_initializer='normal',input_dim = X_train.shape[1]),\n",
    "    Dense(34, activation=\"relu\", kernel_regularizer = regularizers.l2(0.01)),\n",
    "    Dense(64, activation=\"relu\", kernel_regularizer = regularizers.l2(0.01)),\n",
    "    Dense(32, activation=\"relu\", kernel_regularizer = regularizers.l2(0.01)),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['accuracy','mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    validation_split=0.15,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_mae',\n",
    "        patience=20,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc, test_mae = model.evaluate(x=X_test, y=y_test, verbose=0)\n",
    "print('Mean Absolute Error: {acc:0.3f}'.format(acc=test_mae))\n",
    "print('accuracy: {acc:0.3f}'.format(acc=test_acc))\n",
    "print('loss: {acc:0.3f}'.format(acc=test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average Fire Size: {df.fire_size.mean()}\")\n",
    "print(f\"Standard Deviation of Fire Size: {df.fire_size.std()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "df6a2a6d0a1ae49166107b0c1e3b39e060bb8c0d4d18204cd0b91feeca5995f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
